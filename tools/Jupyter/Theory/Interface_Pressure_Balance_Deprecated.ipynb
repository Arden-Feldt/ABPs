{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the import cell\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import matplotlib.ticker as ticker\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import pylab as plot\n",
    "first = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "\n",
    "\n",
    "# Here are my rc parameters for matplotlibf\n",
    "fsize = 20\n",
    "mpl.rc('font', serif='Helvetica Neue')\n",
    "#mpl.rc('font', serif='Times New Roman')\n",
    "mpl.rcParams.update({'font.size': fsize})\n",
    "mpl.rcParams['figure.figsize'] = 3.2, 2.8\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "# Set x tick params\n",
    "mpl.rcParams['xtick.major.size'] = 4.5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['xtick.minor.size'] = 3.\n",
    "mpl.rcParams['xtick.minor.width'] = 1.25\n",
    "# Set y tick params\n",
    "mpl.rcParams['ytick.major.size'] = 4.5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.minor.size'] = 3.\n",
    "mpl.rcParams['ytick.minor.width'] = 1.25\n",
    "mpl.rcParams['legend.fontsize']= 20.\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Load LaTeX and amsmath\n",
    "# mpl.rc('text', usetex=True)\n",
    "# mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current path\n",
    "if first:\n",
    "    parent = os.getcwd()\n",
    "os.chdir(parent)\n",
    "\n",
    "# Grab file names from data folder\n",
    "dens = os.listdir('../../data/txt/Align_press_CoM')\n",
    "try:\n",
    "    data.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres = os.listdir('../../data/txt/Interpart_press')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres2 = os.listdir('../../data/txt/BubComp')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to get the relevant data from the filenames\n",
    "def checkFile(fname, string):\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "#             print\"{} matches {}\".format(fname[i], string[0])\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "#                     print\"{} matches {}\".format(fname[i+j], string[j])\n",
    "                    if j == (len(string) - 1):\n",
    "#                         print\"Final match!\"\n",
    "                        return True\n",
    "                else:\n",
    "                    break\n",
    "    return False\n",
    "    \n",
    "def txtValue(fname, string):\n",
    "    out = \"\"\n",
    "    index = 0\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "                    if j == (len(string) - 1):\n",
    "                        # Last index of search string\n",
    "                        index = i + j\n",
    "                else:\n",
    "                    break\n",
    "                        \n",
    "    # First index of value\n",
    "    index += 1\n",
    "    mybool = True\n",
    "    while mybool:\n",
    "        if fname[index].isdigit():\n",
    "            out = out + fname[index]\n",
    "            index += 1\n",
    "        elif fname[index] == \".\":    \n",
    "            if fname[index+1].isdigit():\n",
    "                out = out + fname[index]\n",
    "                index += 1\n",
    "            else:\n",
    "                mybool = False\n",
    "        else:\n",
    "            mybool = False\n",
    "    return float(out)\n",
    "\n",
    "# Sorting functions\n",
    "def multiSort(arr1, arr2, arr3, arr4):\n",
    "    \"\"\"Sort an array the slow (but certain) way, returns original indices in sorted order\"\"\"\n",
    "    # Doing this for PeR, PeS, xS in this case\n",
    "    cpy1 = np.copy(arr1)\n",
    "    cpy2 = np.copy(arr2)\n",
    "    cpy3 = np.copy(arr3)\n",
    "    cpy4 = np.copy(arr4)\n",
    "    ind = np.arange(0, len(arr1))\n",
    "    for i in range(len(cpy1)):\n",
    "        for j in range(len(cpy1)):\n",
    "            # Sort by first variable\n",
    "            if cpy1[i] > cpy1[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            # If first variable is equal, resort to second variable\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] > cpy2[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] > cpy3[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] == cpy3[j] and cpy4[i] > cpy4[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def indSort(arr1, arr2):\n",
    "    \"\"\"Take sorted index array, use to sort array\"\"\"\n",
    "    # arr1 is array to sort\n",
    "    # arr2 is index array\n",
    "    cpy = np.copy(arr1)\n",
    "    for i in range(len(arr1)):\n",
    "        arr1[i] = cpy[arr2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in dens:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "                \n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(dens, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_dens = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../data/txt/Align_press_CoM')\n",
    "for i in dens:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_dens.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_dens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_dens)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params = params.append(df, ignore_index = True)\n",
    "display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_dens)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_dens[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_dens[0])\n",
    "display(all_dens[0])\n",
    "print(all_dens[0][headers[1]][0])\n",
    "print(all_dens[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../data/txt/Interpart_press')\n",
    "for i in pres:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params2 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params2 = params2.append(df, ignore_index = True)\n",
    "display(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres[0])\n",
    "display(all_pres[0])\n",
    "print(all_pres[0][headers[1]][0])\n",
    "print(all_pres[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres2:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres2, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../data/txt/BubComp')\n",
    "for i in pres2:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params3 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params3 = params3.append(df, ignore_index = True)\n",
    "display(params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new[0])\n",
    "display(all_pres_new[0])\n",
    "print(all_pres_new[0][headers[1]][0])\n",
    "print(all_pres_new[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data is loaded, now compute analytical aspects\n",
    "r_cut = (2.**(1./6.))\n",
    "\n",
    "# Get lattice spacing for particle size\n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / sigma) * ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "# # Lennard-Jones pressure\n",
    "# def ljPress(r, eps, sigma=1.):\n",
    "#     phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "#     div = (sigma/r)\n",
    "#     dU = (24. * eps / r) * ((2.*(div**12.)) - (div)**6.)\n",
    "#     # This is just pressure divided by the area of a particle\n",
    "# #     return (12. * dU / (np.pi * r))\n",
    "#     return (12. * dU / (np.pi * r * phiCP))\n",
    "\n",
    "def ljPress(r, pe, eps, sigma=1.):\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    # This is off by a factor of 1.2...\n",
    "    ljF = avgCollisionForce(pe)\n",
    "    return (2. *np.sqrt(3) * ljF / r)\n",
    "    \n",
    "def avgCollisionForce(pe, power=1.):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    peCritical = 40.\n",
    "    if pe < peCritical:\n",
    "        pe = 0\n",
    "    else:\n",
    "        pe -= peCritical\n",
    "    magnitude = 6.\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "#     return (magnitude * (pe**power)) / (np.pi)\n",
    "#     return (pe * (1. + (8./(np.pi**2.))))\n",
    "    coeff = 1.92#2.03#3.5#2.03\n",
    "    #coeff= 0.4053\n",
    "    return (pe * coeff)\n",
    "\n",
    "def fStar(pe, epsilon, sigma=1.):\n",
    "    out = (avgCollisionForce(pe) * sigma) / (24.*epsilon)\n",
    "    return out\n",
    "    \n",
    "def conForRClust(pe, eps):\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(pe):\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "\n",
    "def nonDimFLJ(r, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "def latForFStar(fstar):\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while nonDimFLJ(r) < fstar:\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "    \n",
    "def latToPhi(latIn):\n",
    "    '''Read in lattice spacing, output phi'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "\n",
    "# From area fraction, get lattice spacing\n",
    "def phiToLat(phiIn):\n",
    "    '''Read in phi, output the lattice spacing'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    latCP = 1.\n",
    "    return np.sqrt(phiCP / phiIn)\n",
    "    \n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    return num / den\n",
    "    \n",
    "def clustFrac(phi, phiG, a, sig=1.):\n",
    "    phiL = latToPhi(a)\n",
    "    ApL = np.pi * (sig**2) / 4.\n",
    "    Ap = np.pi * (sig**2) / 4.\n",
    "    num = (phiL*phiG) - (phiL*phi)\n",
    "    den = (phi*phiG) - (phi*phiL)\n",
    "    ans = num / den\n",
    "    return ans\n",
    "\n",
    "def radCurve(area):\n",
    "    # From area of circle get curvature\n",
    "    return np.sqrt(area/np.pi)\n",
    "\n",
    "def radCirc(circ):\n",
    "    return circ / (2. * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use analytical theory and kinetic theory to get cluster radius\n",
    "epsRange = [1., 0.1, 0.01, 0.001, 0.0001]\n",
    "# epsRange = [0.0001, 0.001, 0.01, 0.1, 1.]\n",
    "peRange = np.arange(0., 700., 1.)\n",
    "phiRange = [0.45, 0.55, 0.65]\n",
    "N = 100000.\n",
    "norm = 10.**0.\n",
    "# norm = 1.\n",
    "\n",
    "phiCP = np.pi / (2. * np.sqrt(3))\n",
    "lat = []\n",
    "pColl = []\n",
    "pLJ = []\n",
    "cfs = []\n",
    "Rls = []\n",
    "peCrit = []\n",
    "phiGs = []\n",
    "phiCPs = []\n",
    "a_box = []\n",
    "l_box = []\n",
    "for b in range(0, len(phiRange)):\n",
    "    lat.append([])\n",
    "    phiCPs.append([])\n",
    "    pColl.append([])\n",
    "    pLJ.append([])\n",
    "    cfs.append([])\n",
    "    Rls.append([])\n",
    "    phiGs.append([])\n",
    "    peCrit.append([])\n",
    "    a_box.append(N * np.pi * 0.25 / phiRange[b])\n",
    "    l_box.append(np.sqrt(a_box[-1]))\n",
    "    for i in range(0, len(epsRange)):\n",
    "        lat[b].append([])\n",
    "        phiCPs[b].append([])\n",
    "        pColl[b].append([])\n",
    "        pLJ[b].append([])\n",
    "        cfs[b].append([])\n",
    "        Rls[b].append([])\n",
    "        phiGs[b].append([])\n",
    "        for j in range(0, len(peRange)):\n",
    "            # Compute lattice spacing\n",
    "        \n",
    "            lat[b][i].append(conForRClust(peRange[j], epsRange[i]))\n",
    "            phiCPs[b][i].append(latToPhi(lat[b][i][-1]))\n",
    "            # Compute pressure\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP)\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP * (lat[b][i][-1]**(0.5)) * 1.25)\n",
    "            curPLJ = ljPress(lat[b][i][-1], peRange[j], epsRange[i])\n",
    "            \n",
    "            # Append to list\n",
    "            pLJ[b][i].append(curPLJ/(norm))\n",
    "\n",
    "            # Compute cluster fraction\n",
    "            phiG = compPhiG(peRange[j], lat[b][i][-1])\n",
    "            phiGs[b][i].append(phiG)\n",
    "            if peRange[j] > 35.:\n",
    "                cf = clustFrac(phiRange[b], phiG, lat[b][i][-1])\n",
    "                if cf < 0. or cf > 1.:\n",
    "                    cf = 0.\n",
    "            else:\n",
    "                cf = 0\n",
    "            cfs[b][i].append(cf)\n",
    "\n",
    "            # Get the critical activity\n",
    "            if j > 0:\n",
    "                if cfs[b][i][-2] == 0. and cfs[b][i][-1] > 0.:\n",
    "                    peCrit[b].append(peRange[j])\n",
    "\n",
    "            # Get the radius (for some N)\n",
    "            Nl = cfs[b][i][-1] * N\n",
    "            Al = Nl * ((np.pi * (lat[b][i][-1]**2))/(4*phiCP))\n",
    "            Rl = np.sqrt(Al / (np.pi))\n",
    "            Rls[b][i].append(Rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "\n",
    "for i in range(0, len(all_dens)):\n",
    "    align_press_total = 0\n",
    "    align_press_vals=0\n",
    "    \n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_dens[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_dens[i]['clust_size'])\n",
    "    for j in range(0, len(all_dens[i]['clust_size'])):\n",
    "        #if all_dens[i]['clust_size'][j]>=0.95*max_size:\n",
    "            align_press = all_dens[i]['press_align'][j]\n",
    "\n",
    "            align_press_total += align_press\n",
    "            align_press_vals += 1\n",
    "    if align_press_vals > 0:        \n",
    "        avg_press = (align_press_total/align_press_vals)\n",
    "        align_press_arr = np.append(align_press_arr, avg_press)\n",
    "        align_peA=np.append(align_peA, params['peA'][i])\n",
    "        align_peB=np.append(align_peB, params['peB'][i])\n",
    "        align_peNet=np.append(align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "        align_xA=np.append(align_xA, params['xA'][i])\n",
    "        align_phi=np.append(align_phi, params['phi'][i])\n",
    "        align_eps=np.append(align_eps, params['eps'][i])\n",
    "\n",
    "    \n",
    "interpart_peA=np.array([])\n",
    "interpart_peB=np.array([])\n",
    "interpart_peNet=np.array([])\n",
    "interpart_xA=np.array([])\n",
    "interpart_eps=np.array([])\n",
    "interpart_pnum=np.array([])\n",
    "interpart_phi=np.array([])\n",
    "interpart_press=np.array([])\n",
    "interpart_press_expand=np.array([])\n",
    "avg_shear=np.array([])\n",
    "for i in range(0, len(all_pres)):\n",
    "    bulk_press_total = 0\n",
    "    bulk_press_total_expand = 0\n",
    "    bulk_press_vals=0\n",
    "    shear_press_expand=0\n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_pres[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_pres[i]['NDense'])\n",
    "    for j in range(0, len(all_pres[i]['NDense'])):\n",
    "        #if all_pres[i]['NDense'][j]>=0.95*max_size:\n",
    "        \n",
    "            bulk_trace = (all_pres[i]['bulkSigXX'].iloc[j]+all_pres[i]['bulkSigYY'].iloc[j])/2#+all_pres_new[i]['bulkSigYX'].iloc[-1]+all_pres_new[i]['bulkSigYY'].iloc[-1])/2\n",
    "            bulk_press = bulk_trace / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            \n",
    "            bulk_trace_expand = (all_pres[i]['bulkSigXX'].iloc[j]+all_pres[i]['bulkSigXY'].iloc[j]+all_pres[i]['bulkSigYX'].iloc[j]+all_pres[i]['bulkSigYY'].iloc[j])/2\n",
    "            bulk_press_expand = bulk_trace_expand / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            \n",
    "            shear_stress = (all_pres[i]['bulkSigXY'].iloc[j]+all_pres[i]['bulkSigYX'].iloc[j])/2\n",
    "            shear_press = shear_stress / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            if bulk_press > 0:\n",
    "                shear_press_expand +=shear_press\n",
    "                bulk_press_total += bulk_press\n",
    "                bulk_press_total_expand += bulk_press_expand\n",
    "                bulk_press_vals += 1\n",
    "    if bulk_press_vals > 0:        \n",
    "        avg_shear = np.append(avg_shear, shear_press_expand/bulk_press_vals)\n",
    "        avg_press = (bulk_press_total/(2*bulk_press_vals))\n",
    "        avg_press_expand = (bulk_press_total_expand/bulk_press_vals)\n",
    "        interpart_press=np.append(interpart_press, avg_press)\n",
    "        interpart_press_expand=np.append(interpart_press_expand, avg_press_expand)\n",
    "        interpart_peA=np.append(interpart_peA, params2['peA'][i])\n",
    "        interpart_peB=np.append(interpart_peB, params2['peB'][i])\n",
    "        interpart_peNet=np.append(interpart_peNet, params2['peB'][i] * (1-params2['xA'][i]/100) + params2['peA'][i] * (params2['xA'][i]/100))\n",
    "        interpart_xA=np.append(interpart_xA, params2['xA'][i])\n",
    "        interpart_phi=np.append(interpart_phi, params2['phi'][i])\n",
    "        interpart_eps=np.append(interpart_eps, params2['eps'][i])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(interpart_peNet, interpart_press, c='blue', label='bulk interparticle')\n",
    "plt.scatter(align_peNet, align_press_arr, c='red', label='aligned interface')\n",
    "plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "'''\n",
    "for i in range(0, len(align_peA)):  \n",
    "    for j in range(0, len(align_peB)):  \n",
    "        for k in range(0, len(interpart_peA)):  \n",
    "            for l in range(0, len(interpart_peB)):  \n",
    "                if (align_peA[i]==interpart_peA[k]) & (align_peB[j]==interpart_peB[l]):\n",
    "                    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeVel(activity):\n",
    "    \"Given particle activity, output intrinsic swim speed\"\n",
    "    # This gives:\n",
    "    # v_0 = Pe * sigma / tau_B = Pe * sigma / 3 * tau_R\n",
    "    velocity = (activity * sigma) / (3 * (1/D_r))\n",
    "    return velocity\n",
    "\n",
    "def computeActiveForce(velocity):\n",
    "    \"Given particle activity, output repulsion well depth\"\n",
    "    # This is multiplied by Brownian time and gives:\n",
    "    #          Pe = 3 * v_0 * tau_R / sigma\n",
    "    # the conventional description of the Peclet number\n",
    "    activeForce = velocity * threeEtaPiSigma\n",
    "    return activeForce\n",
    "\n",
    "def computeEps(alpha, activeForce):\n",
    "    \"Given particle activity, output repulsion well depth\"\n",
    "    # Here is where we will be testing the ratio we use (via alpha)\n",
    "    epsilon = (alpha * activeForce * sigma / 24.0) + 1.0\n",
    "    # Add 1 because of integer rounding\n",
    "    epsilon = int(epsilon) + 1\n",
    "    return epsilon\n",
    "\n",
    "def computeTauLJ(epsilon):\n",
    "    \"Given epsilon, compute lennard-jones time unit\"\n",
    "    tauLJ = ((sigma**2) * threeEtaPiSigma) / epsilon\n",
    "    return tauLJ\n",
    "\n",
    "\n",
    "def compPeNet(xf, pes, pef):\n",
    "    peNet = (pes * (1.-xf)) + (pef * xf)\n",
    "    return peNet\n",
    "def avgCollisionForce(peNet):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "    return (magnitude * peNet) / (np.pi)  \n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    '''Compute the Lennard-Jones force'''\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / r) * ((2*(div**12)) - (div)**6)\n",
    "    return dU\n",
    "\n",
    "# Lennard-Jones pressure\n",
    "def ljPress(r, pe, eps, sigma=1.):\n",
    "    '''\n",
    "    Purpose: Take epsilon (magnitude of lennard-jones force), sigma (particle diameter),\n",
    "    activity (pe), and separation distance (r) of 2 particles to compute pressure from\n",
    "    avg compressive active forces from neighbors\n",
    "    \n",
    "    Inputs: \n",
    "        r: Separation distance in simulation units\n",
    "        epsilon: magnitude of lennard-jones potential\n",
    "        pe: activity (peclet number)\n",
    "        sigma: particle diameter (default=1.0)\n",
    "    \n",
    "    Output: Analytical virial pressure (see monodisperse paper for derivation)\n",
    "    '''\n",
    "    #Area fraction at HCP\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    \n",
    "    # LJ force\n",
    "    ljF = avgCollisionForce(pe)\n",
    "    \n",
    "    return (2. *np.sqrt(3) * ljF / r)\n",
    "\n",
    "def getLat(peNet, eps):\n",
    "    '''Get the lattice spacing for any pe'''\n",
    "    if peNet == 0:\n",
    "        return 2.**(1./6.)\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(peNet):\n",
    "            r -= j\n",
    "        r += j\n",
    "    return r  \n",
    "def latToPhi(latIn):\n",
    "    '''Read in lattice spacing, output phi'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "def clustFrac(phi, phiG, aF, aS, xF, sig=1.):\n",
    "    '''Compute the fraction of particles in the cluster'''\n",
    "    if xF == 0.:\n",
    "        phiLS = latToPhi(aS)\n",
    "        phiLF = 1.\n",
    "    elif xF == 1.:\n",
    "        phiLS = 1.\n",
    "        phiLF = latToPhi(aF)\n",
    "    else:\n",
    "        phiLS = latToPhi(aS)\n",
    "        phiLF = latToPhi(aF)\n",
    "    coeff = (phiG - phi) / phi\n",
    "    num = phiLF * phiLS\n",
    "    den = ( phiG * ((phiLS*xF) + (phiLF*(1.-xF))) ) - (phiLF * phiLS)\n",
    "    ans = coeff * num / den\n",
    "    return ans\n",
    "#Calculate gas phase area fraction\n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    '''\n",
    "    Purpose: Compute analytical area fraction of the gas phase at steady state\n",
    "    given activity and lattice spacing\n",
    "    \n",
    "    Inputs: \n",
    "        pe: net activity (peclet number)\n",
    "        a: lattice spacing \n",
    "        kap: fitting parameter (default=4.5, shown by Redner)\n",
    "        sig: particle diameter (default=1.0)\n",
    "    \n",
    "    Output: Area fraction of the gas phase at steady state\n",
    "    '''\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    return num / den\n",
    "# Calculate dense phase area fraction from lattice spacing\n",
    "def latToPhi(latIn):\n",
    "    '''\n",
    "    Purpose: Compute analytical area fraction of the dense phase given the lattice\n",
    "    spacing.\n",
    "    \n",
    "    Inputs: \n",
    "        latIn: lattice spacing\n",
    "    \n",
    "    Output: dense phase area fraction\n",
    "    '''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "\n",
    "# Use latNet to space your particles\n",
    "def computeDistance(x, y):\n",
    "    return np.sqrt((x**2) + (y**2))\n",
    " \n",
    "def interDist(x1, y1, x2, y2):\n",
    "    return np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "  \n",
    "def orientToOrigin(x, y, act):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    x *= -1.\n",
    "    y *= -1.\n",
    "    hypRatio = act / np.sqrt(x**2 + y**2)\n",
    "    xAct = hypRatio * x\n",
    "    yAct = hypRatio * y\n",
    "    return xAct, yAct\n",
    "\n",
    "def densProbability(r, activity_net, activity_slow):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    gas_dense_dif_phi = 0.866 * np.log10(activity_net - 46.993) - 0.443\n",
    "    rate_decay = -6.151 * np.log10(activity_net-49.921) - 4.392\n",
    "    mid_point = 0.044 * np.log10(activity_slow-49.893) + 0.836\n",
    "    gas_phi = -0.26 * np.log10(activity_slow-41.742)+0.783\n",
    "    \n",
    "    num_dens_r = ((gas_dense_dif_phi / (1+np.exp(-rate_decay * (r-mid_point)))) + gas_phi)\n",
    "    \n",
    "    return num_dens_r\n",
    "\n",
    "def alignProbability(r, activity_net, activity_slow):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    max_align = 0.2019 * np.log10(activity_net - 41.2803) - 0.1885\n",
    "    mid_point = 0.0492 * np.log10(activity_slow - 47.0061) + 0.8220\n",
    "    std_dev = 0.1057\n",
    "    align_r = max_align * np.exp(-(r-mid_point)**2/(2*std_dev**2))\n",
    "    \n",
    "    return align_r\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return int(idx)\n",
    "\n",
    "def activityProbability(r, r_swap = [], probA = []):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    if len(r_swap)>0:\n",
    "        prob_rA = np.zeros(len(r))\n",
    "        prob_rB = np.zeros(len(r))\n",
    "        for i in range(1, len(r_swap)):\n",
    "            r_min = find_nearest(r, r_swap[i-1])\n",
    "            r_max = find_nearest(r, r_swap[i])\n",
    "            \n",
    "            prob_rA[r_min:r_max+1]=probA[i]\n",
    "            prob_rB[r_min:r_max+1]=1.0-probA[i]\n",
    "    \n",
    "    return prob_rA, prob_rB\n",
    "\n",
    "xF = 0.5\n",
    "xS = 0.5\n",
    "eps=1.0\n",
    "partNum=50000\n",
    "peS_arr = np.linspace(50, 500, num=200)\n",
    "peF_arr = np.linspace(50, 500, num=200)\n",
    "\n",
    "peNet_int_arr = np.array([])\n",
    "peS_int_arr = np.array([])\n",
    "peF_int_arr = np.array([])\n",
    "bulk_theory_arr = np.array([])\n",
    "press_int_arr = np.array([])\n",
    "for i in range(0, len(peS_arr)):\n",
    "    for j in range(0, len(peF_arr)):\n",
    "        print(i)\n",
    "        peS = peS_arr[i]\n",
    "        peF = peF_arr[j]\n",
    "        pa = peS_arr[i]\n",
    "        pb = peF_arr[j]\n",
    "        peNet = compPeNet(xF, peS, peF)\n",
    "    \n",
    "        # Compute lattice spacing based on each activity\n",
    "        latS = getLat(peS, eps)\n",
    "        latF = getLat(peF, eps)\n",
    "        latNet = getLat(peNet, eps)\n",
    "        latF=latNet\n",
    "        latS=latNet\n",
    "        \n",
    "        # Compute gas phase density, phiG\n",
    "        phiG = compPhiG(peNet, latNet)\n",
    "        phi_theory = latToPhi(latNet)\n",
    "\n",
    "        Nl = int(round(partNum * ((phi_theory * (phiG - phi)) / (phi * (phiG - phi_theory)))))\n",
    "\n",
    "        # Now you need to convert this to a cluster radius\n",
    "        phiCP = np.pi / (2. * np.sqrt(3))\n",
    "        \n",
    "        # The area is the sum of the particle areas (normalized by close packing density of spheres)\n",
    "        Al = (Nl * np.pi * (latNet)**2) / (4*phiCP)\n",
    "        \n",
    "        # The cluster radius is the square root of liquid area divided by pi\n",
    "        Rl = np.sqrt(Al / np.pi)\n",
    "\n",
    "        r_arr = np.linspace(0, 2, num=400)\n",
    "        probA_fast_out = [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
    "        probA_random =   [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
    "        prob_arr_A, prob_arr_B = activityProbability(r_arr, r_swap = [0.0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0], probA=probA_random)\n",
    "\n",
    "        dens = densProbability(r_arr, peNet, peS)\n",
    "        align = alignProbability(r_arr, peNet, peS)\n",
    "        press = dens * align * (prob_arr_A * pa + prob_arr_B * pb)\n",
    "\n",
    "        press_int = 0\n",
    "        for k in range(1, len(press)):\n",
    "            press_int += ((press[k-1]+press[k])/2)*(r_arr[k]-r_arr[k-1]) * Rl\n",
    "        bulk_theory_arr = np.append(bulk_theory_arr, 4*np.sqrt(3)*peNet / latNet)\n",
    "        press_int_arr = np.append(press_int_arr, press_int)\n",
    "        peS_int_arr = np.append(peS_int_arr, peS)\n",
    "        peF_int_arr = np.append(peF_int_arr, peF)\n",
    "        peNet_int_arr = np.append(peNet_int_arr, peNet)\n",
    "        #print(press_int)\n",
    "        #press_interpart = 4 * np.sqrt(3) * (peNet-50) / latNet\n",
    "        #print(press_interpart)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "#plt.scatter(interpart_peNet, interpart_press, s=10.0, color='blue', label='bulk interparticle')\n",
    "plt.scatter(peNet_int_arr, press_int_arr, s=15.0, color='black', label=r'$\\Pi_\\mathrm{i}$ Theory')\n",
    "plt.scatter(interpart_peNet, interpart_press, c='turquoise', label='$\\Pi_\\mathrm{d}$ Simulation')\n",
    "plt.scatter(peNet_int_arr, bulk_theory_arr, c='green', label=r'$\\Pi_\\mathrm{d}$ Theory')\n",
    "\n",
    "#plt.scatter(align_peNet, align_press_arr, s=15.0, color='red', label='Simulation')\n",
    "\n",
    "\n",
    "plt.ylabel(r'Pressure')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.ylim([-2500, 25000])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "\n",
    "\n",
    "for i in range(0, len(all_dens)):\n",
    "    \n",
    "    align_time =np.array([])\n",
    "    align_press_time = np.array([])\n",
    "    align_press_total = 0\n",
    "    align_press_vals=0\n",
    "    \n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_dens[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_dens[i]['clust_size'])\n",
    "    for j in range(0, len(all_dens[i]['clust_size'])):\n",
    "        #if all_dens[i]['clust_size'][j]>=0.95*max_size:\n",
    "            int_id = all_dens[i]['interface_id'][j]\n",
    "            if int_id == 1:\n",
    "                align_press = all_dens[i]['press_align_bub1'][j]\n",
    "            elif int_id == 2:\n",
    "                align_press = all_dens[i]['press_align_bub2'][j]\n",
    "            elif int_id == 3:\n",
    "                align_press = all_dens[i]['press_align_bub3'][j]\n",
    "            elif int_id == 4:\n",
    "                align_press = all_dens[i]['press_align_bub4'][j]\n",
    "            elif int_id == 5:\n",
    "                align_press = all_dens[i]['press_align_bub5'][j]\n",
    "            if align_press > 0:\n",
    "                align_time = np.append(align_time, all_dens[i]['tauB'].iloc[j])\n",
    "                align_press_time = np.append(align_press_time, align_press)\n",
    "            \n",
    "                align_press_total += align_press\n",
    "                align_press_vals += 1\n",
    "    if align_press_vals > 50:        \n",
    "        avg_press = (align_press_total/align_press_vals)\n",
    "        align_press_arr = np.append(align_press_arr, avg_press)\n",
    "        align_peA=np.append(align_peA, params['peA'][i])\n",
    "        align_peB=np.append(align_peB, params['peB'][i])\n",
    "        align_peNet=np.append(align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "        align_xA=np.append(align_xA, params['xA'][i])\n",
    "        align_phi=np.append(align_phi, params['phi'][i])\n",
    "        align_eps=np.append(align_eps, params['eps'][i])\n",
    "    for k in range(0, len(all_pres)):\n",
    "        if params2['peA'][k]==params['peA'][i]:\n",
    "            if params2['peB'][k]==params['peB'][i]:\n",
    "                if params2['eps'][k]==params['eps'][i]:\n",
    "                    if params2['phi'][k]==params['phi'][i]:\n",
    "                        if params2['xA'][k]==params['xA'][i]:\n",
    "                            bulk_time =np.array([])\n",
    "                            bulk_press_time = np.array([])\n",
    "                            bulk_press_total = 0\n",
    "                            bulk_press_total_expand = 0\n",
    "                            bulk_press_vals=0\n",
    "                            shear_press_expand=0\n",
    "                            # Don't plot non-phase-separated data\n",
    "                            if all_pres[k].empty:\n",
    "                                    continue\n",
    "\n",
    "\n",
    "                            max_size = np.amax(all_pres[k]['NDense'])\n",
    "                            for l in range(0, len(all_pres[k]['NDense'])):\n",
    "                                #if all_pres[i]['NDense'][j]>=0.95*max_size:\n",
    "\n",
    "                                    bulk_trace = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2#+all_pres_new[i]['bulkSigYX'].iloc[-1]+all_pres_new[i]['bulkSigYY'].iloc[-1])/2\n",
    "                                    bulk_press = bulk_trace / (all_pres[k]['bulkArea'].iloc[l])\n",
    "\n",
    "                                    bulk_trace_expand = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2\n",
    "                                    bulk_press_expand = bulk_trace_expand / (all_pres[k]['bulkArea'].iloc[l])\n",
    "\n",
    "                                    shear_stress = (all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l])/2\n",
    "                                    shear_press = shear_stress / (all_pres[k]['bulkArea'].iloc[l])\n",
    "                                    if bulk_press>0:\n",
    "                                        bulk_time = np.append(bulk_time, all_pres[k]['Timestep'].iloc[l])\n",
    "                                        bulk_press_time = np.append(bulk_press_time, bulk_press/2)\n",
    "                                        shear_press_expand +=shear_press\n",
    "                                        bulk_press_total += bulk_press\n",
    "                                        bulk_press_total_expand += bulk_press_expand\n",
    "                                        bulk_press_vals += 1\n",
    "                            if bulk_press_vals > 50:        \n",
    "                                avg_shear = np.append(avg_shear, shear_press_expand/bulk_press_vals)\n",
    "                                avg_press = (bulk_press_total/(2*bulk_press_vals))\n",
    "                                avg_press_expand = (bulk_press_total_expand/bulk_press_vals)\n",
    "                                interpart_press=np.append(interpart_press, avg_press)\n",
    "                                interpart_press_expand=np.append(interpart_press_expand, avg_press_expand)\n",
    "                                interpart_peA=np.append(interpart_peA, params2['peA'][k])\n",
    "                                interpart_peB=np.append(interpart_peB, params2['peB'][k])\n",
    "                                interpart_peNet=np.append(interpart_peNet, params2['peB'][k] * (1-params2['xA'][k]/100) + params2['peA'][k] * (params2['xA'][k]/100))\n",
    "                                interpart_xA=np.append(interpart_xA, params2['xA'][k])\n",
    "                                interpart_phi=np.append(interpart_phi, params2['phi'][k])\n",
    "                                interpart_eps=np.append(interpart_eps, params2['eps'][k])\n",
    "                            \n",
    "                            plt.plot(bulk_time, bulk_press_time, color='blue')\n",
    "                            plt.scatter(align_time, align_press_time, s=0.7, color='red')\n",
    "                            plt.show()\n",
    "\n",
    "    \n",
    "interpart_peA=np.array([])\n",
    "interpart_peB=np.array([])\n",
    "interpart_peNet=np.array([])\n",
    "interpart_xA=np.array([])\n",
    "interpart_eps=np.array([])\n",
    "interpart_pnum=np.array([])\n",
    "interpart_phi=np.array([])\n",
    "interpart_press=np.array([])\n",
    "interpart_press_expand=np.array([])\n",
    "avg_shear=np.array([])\n",
    "\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(interpart_peNet, interpart_press, c='blue', label='bulk interparticle')\n",
    "plt.scatter(align_peNet, align_press_arr, c='red', label='aligned interface')\n",
    "plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "'''\n",
    "for i in range(0, len(align_peA)):  \n",
    "    for j in range(0, len(align_peB)):  \n",
    "        for k in range(0, len(interpart_peA)):  \n",
    "            for l in range(0, len(interpart_peB)):  \n",
    "                if (align_peA[i]==interpart_peA[k]) & (align_peB[j]==interpart_peB[l]):\n",
    "                    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
