{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the import cell\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import matplotlib.ticker as ticker\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import pylab as plot\n",
    "first = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "\n",
    "\n",
    "# Here are my rc parameters for matplotlibf\n",
    "fsize = 20\n",
    "mpl.rc('font', serif='Helvetica Neue')\n",
    "#mpl.rc('font', serif='Times New Roman')\n",
    "mpl.rcParams.update({'font.size': fsize})\n",
    "mpl.rcParams['figure.figsize'] = 3.2, 2.8\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "# Set x tick params\n",
    "mpl.rcParams['xtick.major.size'] = 4.5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['xtick.minor.size'] = 3.\n",
    "mpl.rcParams['xtick.minor.width'] = 1.25\n",
    "# Set y tick params\n",
    "mpl.rcParams['ytick.major.size'] = 4.5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.minor.size'] = 3.\n",
    "mpl.rcParams['ytick.minor.width'] = 1.25\n",
    "mpl.rcParams['legend.fontsize']= 20.\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Load LaTeX and amsmath\n",
    "# mpl.rc('text', usetex=True)\n",
    "# mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current path\n",
    "if first:\n",
    "    parent = os.getcwd()\n",
    "print(parent)\n",
    "# Grab file names from data folder\n",
    "dens = os.listdir('../../../../../../../../Volumes/EXTERNAL2/leakage_final')\n",
    "\n",
    "try:\n",
    "    dens.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres2 = os.listdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/BubComp')\n",
    "try:\n",
    "    pres2.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres3 = os.listdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/PhaseComp')\n",
    "try:\n",
    "    pres3.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres5 = os.listdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/lat_end')\n",
    "try:\n",
    "    pres5.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to get the relevant data from the filenames\n",
    "def checkFile(fname, string):\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "#             print\"{} matches {}\".format(fname[i], string[0])\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "#                     print\"{} matches {}\".format(fname[i+j], string[j])\n",
    "                    if j == (len(string) - 1):\n",
    "#                         print\"Final match!\"\n",
    "                        return True\n",
    "                else:\n",
    "                    break\n",
    "    return False\n",
    "    \n",
    "def txtValue(fname, string):\n",
    "    out = \"\"\n",
    "    index = 0\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "                    if j == (len(string) - 1):\n",
    "                        # Last index of search string\n",
    "                        index = i + j\n",
    "                else:\n",
    "                    break\n",
    "                        \n",
    "    # First index of value\n",
    "    index += 1\n",
    "    mybool = True\n",
    "    while mybool:\n",
    "        if fname[index].isdigit():\n",
    "            out = out + fname[index]\n",
    "            index += 1\n",
    "        elif fname[index] == \".\":    \n",
    "            if fname[index+1].isdigit():\n",
    "                out = out + fname[index]\n",
    "                index += 1\n",
    "            else:\n",
    "                mybool = False\n",
    "        else:\n",
    "            mybool = False\n",
    "    return float(out)\n",
    "\n",
    "# Sorting functions\n",
    "def multiSort(arr1, arr2, arr3, arr4):\n",
    "    \"\"\"Sort an array the slow (but certain) way, returns original indices in sorted order\"\"\"\n",
    "    # Doing this for PeR, PeS, xS in this case\n",
    "    cpy1 = np.copy(arr1)\n",
    "    cpy2 = np.copy(arr2)\n",
    "    cpy3 = np.copy(arr3)\n",
    "    cpy4 = np.copy(arr4)\n",
    "    ind = np.arange(0, len(arr1))\n",
    "    for i in range(len(cpy1)):\n",
    "        for j in range(len(cpy1)):\n",
    "            # Sort by first variable\n",
    "            if cpy1[i] > cpy1[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            # If first variable is equal, resort to second variable\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] > cpy2[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] > cpy3[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] == cpy3[j] and cpy4[i] > cpy4[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def indSort(arr1, arr2):\n",
    "    \"\"\"Take sorted index array, use to sort array\"\"\"\n",
    "    # arr1 is array to sort\n",
    "    # arr2 is index array\n",
    "    cpy = np.copy(arr1)\n",
    "    for i in range(len(arr1)):\n",
    "        arr1[i] = cpy[arr2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in dens:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "                \n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(dens, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_dens = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/leakage_final')\n",
    "for i in dens:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_dens.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_dens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_dens)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params = params.append(df, ignore_index = True)\n",
    "display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_dens)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_dens[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_dens[0])\n",
    "display(all_dens[0])\n",
    "print(all_dens[0][headers[1]][0])\n",
    "print(all_dens[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres2:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres2, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/BubComp')\n",
    "for i in pres2:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params3 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params3 = params3.append(df, ignore_index = True)\n",
    "display(params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new[0])\n",
    "display(all_pres_new[0])\n",
    "print(all_pres_new[0][headers[1]][0])\n",
    "print(all_pres_new[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres3:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres3, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new2 = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/PhaseComp')\n",
    "for i in pres3:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new2.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new2[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params4 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new2)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params4 = params4.append(df, ignore_index = True)\n",
    "display(params4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new2)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new2[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new2[0])\n",
    "display(all_pres_new2[0])\n",
    "print(all_pres_new2[0][headers[1]][0])\n",
    "print(all_pres_new2[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres5:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres5, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new4 = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/final_videos/txt_files_final/lat_end')\n",
    "for i in pres5:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new4.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new4[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params6 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new4)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params6 = params6.append(df, ignore_index = True)\n",
    "display(params6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new4)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new4[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new4[0])\n",
    "display(all_pres_new4[0])\n",
    "print(all_pres_new4[0][headers[1]][0])\n",
    "print(all_pres_new4[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gas_to_bulk_mean = np.array([])\n",
    "slow_gas_to_bulk_mean = np.array([])\n",
    "fast_gas_to_bulk_mean = np.array([])\n",
    "\n",
    "gas_to_int_mean = np.array([])\n",
    "slow_gas_to_int_mean = np.array([])\n",
    "fast_gas_to_int_mean = np.array([])\n",
    "\n",
    "bulk_to_int_mean = np.array([])\n",
    "slow_bulk_to_int_mean = np.array([])\n",
    "fast_bulk_to_int_mean = np.array([])\n",
    "\n",
    "bulk_to_gas_mean = np.array([])\n",
    "slow_bulk_to_gas_mean = np.array([])\n",
    "fast_bulk_to_gas_mean = np.array([])\n",
    "\n",
    "int_to_gas_mean = np.array([])\n",
    "slow_int_to_gas_mean = np.array([])\n",
    "fast_int_to_gas_mean = np.array([])\n",
    "\n",
    "int_to_bulk_mean = np.array([])\n",
    "slow_int_to_bulk_mean = np.array([])\n",
    "fast_int_to_bulk_mean = np.array([])\n",
    "\n",
    "slow_act = np.array([])\n",
    "fast_act = np.array([])\n",
    "\n",
    "time=np.array([])\n",
    "\n",
    "bulk_lat_mean_mean = np.array([])\n",
    "\n",
    "bulk_nA_mean = np.array([])\n",
    "bulk_nB_mean = np.array([])\n",
    "bulk_n_mean = np.array([])\n",
    "\n",
    "\n",
    "int_n_mean = np.array([])\n",
    "int_nA_mean =np.array([])\n",
    "int_nB_mean =np.array([])\n",
    "\n",
    "gas_n_mean =np.array([])\n",
    "gas_nA_mean = np.array([])\n",
    "gas_nB_mean = np.array([])\n",
    "\n",
    "dense_n_mean = np.array([])\n",
    "dense_nA_mean = np.array([])\n",
    "dense_nB_mean = np.array([])\n",
    "adsorp_rate = np.array([])  \n",
    "\n",
    "bub_width_mean = np.array([])\n",
    "bub_surface_area_mean = np.array([])\n",
    "int_width_mean = np.array([])\n",
    "for q in range(0, len(all_dens)):\n",
    "    if all_dens[q].empty:\n",
    "            continue\n",
    "    #if params['peA'][q]==params['peB'][q]:\n",
    "    for r in range(0, len(all_pres_new2)):\n",
    "        if (params4['peA'][r] == params['peA'][q]) & (params4['peB'][r] == params['peB'][q]):\n",
    "            if all_pres_new2[r].empty:\n",
    "                continue\n",
    "            for s in range(0, len(all_pres_new4)):\n",
    "                if (params6['peA'][s] == params['peA'][q]) & (params6['peB'][s] == params['peB'][q]):\n",
    "                    if all_pres_new4[s].empty:\n",
    "                        continue\n",
    "                    for t in range(0, len(all_pres_new)):\n",
    "                        if (params3['peA'][t] == params['peA'][q]) & (params3['peB'][t] == params['peB'][q]):\n",
    "                            if all_pres_new[t].empty:\n",
    "                                continue\n",
    "                            gas_to_bulk = np.array([])\n",
    "                            slow_gas_to_bulk = np.array([])\n",
    "                            fast_gas_to_bulk = np.array([])\n",
    "\n",
    "                            gas_to_int = np.array([])\n",
    "                            slow_gas_to_int = np.array([])\n",
    "                            fast_gas_to_int = np.array([])\n",
    "\n",
    "                            bulk_to_int = np.array([])\n",
    "                            slow_bulk_to_int = np.array([])\n",
    "                            fast_bulk_to_int = np.array([])\n",
    "\n",
    "                            bulk_to_gas = np.array([])\n",
    "                            slow_bulk_to_gas = np.array([])\n",
    "                            fast_bulk_to_gas = np.array([])\n",
    "\n",
    "                            int_to_gas = np.array([])\n",
    "                            slow_int_to_gas = np.array([])\n",
    "                            fast_int_to_gas = np.array([])\n",
    "\n",
    "                            int_to_bulk = np.array([])\n",
    "                            slow_int_to_bulk = np.array([])\n",
    "                            fast_int_to_bulk = np.array([])\n",
    "\n",
    "                            bulk_nA_arr = np.array([])\n",
    "                            bulk_nB_arr = np.array([])\n",
    "                            bulk_n_arr = np.array([])\n",
    "                            time=np.array([])\n",
    "\n",
    "\n",
    "                            int_n_arr = np.array([])\n",
    "                            int_nA_arr =np.array([])\n",
    "                            int_nB_arr =np.array([])\n",
    "\n",
    "                            gas_n_arr =np.array([])\n",
    "                            gas_nA_arr = np.array([])\n",
    "                            gas_nB_arr = np.array([])\n",
    "\n",
    "                            dense_n_arr = np.array([])\n",
    "                            dense_nA_arr = np.array([])\n",
    "                            dense_nB_arr = np.array([])\n",
    "\n",
    "                            bulk_lat_mean = np.array([])\n",
    "\n",
    "                            bub_width_arr = np.array([])\n",
    "                            bub_surface_area_arr = np.array([])\n",
    "                            int_width_arr = np.array([])\n",
    "\n",
    "\n",
    "            #if (params4['peA'][q]>=0) & (params4['peB'][q]>=0):\n",
    "\n",
    "                            bin_size = all_pres_new2[q]['sizeBin']\n",
    "                            bin_area = bin_size**2\n",
    "                            bulk_nA_arr = np.append(bulk_nA_arr, all_pres_new2[q]['Na_bulk'] / (bin_area * all_pres_new2[q]['NBin_bulk']))\n",
    "                            bulk_nB_arr = np.append(bulk_nB_arr, all_pres_new2[q]['Nb_bulk'] / (bin_area * all_pres_new2[q]['NBin_bulk']))\n",
    "                            bulk_n_arr = np.append(bulk_n_arr, (all_pres_new2[q]['Nb_bulk']+all_pres_new2[q]['Na_bulk']) / (bin_area * all_pres_new2[q]['NBin_bulk']))\n",
    "\n",
    "\n",
    "                            int_n_arr = np.append(int_n_arr, (all_pres_new2[q]['Na_int']+all_pres_new2[q]['Nb_int']) / (bin_area * all_pres_new2[q]['NBin_int']))\n",
    "                            int_nA_arr = np.append(int_nA_arr, all_pres_new2[q]['Na_int'] / (bin_area * all_pres_new2[q]['NBin_int']))\n",
    "                            int_nB_arr = np.append(int_nB_arr, all_pres_new2[q]['Nb_int'] / (bin_area * all_pres_new2[q]['NBin_int']))\n",
    "\n",
    "                            gas_n_arr = np.append(gas_n_arr, (all_pres_new2[q]['Na_gas'] + all_pres_new2[q]['Nb_gas']) / (bin_area * all_pres_new2[q]['NBin_gas']))\n",
    "                            gas_nA_arr = np.append(gas_nA_arr, all_pres_new2[q]['Na_gas'] / (bin_area * all_pres_new2[q]['NBin_gas']))\n",
    "                            gas_nB_arr = np.append(gas_nB_arr, all_pres_new2[q]['Nb_gas'] / (bin_area * all_pres_new2[q]['NBin_gas']))\n",
    "\n",
    "                            dense_n_arr = np.append(dense_n_arr, (all_pres_new2[q]['Na_int']+all_pres_new2[q]['Nb_int']+all_pres_new2[q]['Na_bulk']+all_pres_new2[q]['Nb_bulk']) / (bin_area * (all_pres_new2[q]['NBin_int']+all_pres_new2[q]['NBin_bulk'])))\n",
    "                            dense_nA_arr = np.append(dense_nA_arr, (all_pres_new2[q]['Na_int']+all_pres_new2[q]['Na_bulk']) / (bin_area * (all_pres_new2[q]['NBin_int']+all_pres_new2[q]['NBin_bulk'])))\n",
    "                            dense_nB_arr = np.append(dense_nB_arr, (all_pres_new2[q]['Nb_int']+all_pres_new2[q]['Nb_bulk']) / (bin_area * (all_pres_new2[q]['NBin_int']+all_pres_new2[q]['NBin_bulk'])))\n",
    "\n",
    "\n",
    "                            time = np.append(time, all_dens[q]['tst'])\n",
    "\n",
    "                            gas_to_bulk = np.append(gas_to_bulk, all_dens[q]['Ngas_to_bulk'])\n",
    "                            slow_gas_to_bulk = np.append(slow_gas_to_bulk, all_dens[q]['Nsgas_to_bulk'])\n",
    "                            fast_gas_to_bulk = np.append(fast_gas_to_bulk, all_dens[q]['Nfgas_to_bulk'])\n",
    "\n",
    "                            bulk_to_gas = np.append(bulk_to_gas, all_dens[q]['Nbulk_to_gas'])\n",
    "                            slow_bulk_to_gas = np.append(slow_bulk_to_gas, all_dens[q]['Nsbulk_to_gas'])\n",
    "                            fast_bulk_to_gas = np.append(fast_bulk_to_gas, all_dens[q]['Nfbulk_to_gas'])\n",
    "\n",
    "                            gas_to_int = np.append(gas_to_int, all_dens[q]['Ngas_to_int'])\n",
    "                            slow_gas_to_int = np.append(slow_gas_to_int, all_dens[q]['Nsgas_to_int'])\n",
    "                            fast_gas_to_int = np.append(fast_gas_to_int, all_dens[q]['Nfgas_to_int'])\n",
    "\n",
    "                            bulk_to_int = np.append(bulk_to_int, all_dens[q]['Nbulk_to_int'])\n",
    "                            slow_bulk_to_int = np.append(slow_bulk_to_int, all_dens[q]['Nsbulk_to_int'])\n",
    "                            fast_bulk_to_int = np.append(fast_bulk_to_int, all_dens[q]['Nfbulk_to_int'])\n",
    "\n",
    "                            int_to_bulk = np.append(int_to_bulk, all_dens[q]['Nint_to_bulk'])\n",
    "                            slow_int_to_bulk = np.append(slow_int_to_bulk, all_dens[q]['Nsint_to_bulk'])\n",
    "                            fast_int_to_bulk = np.append(fast_int_to_bulk, all_dens[q]['Nfint_to_bulk'])\n",
    "\n",
    "                            int_to_gas = np.append(int_to_gas, all_dens[q]['Nint_to_gas'])\n",
    "                            slow_int_to_gas = np.append(slow_int_to_gas, all_dens[q]['Nsint_to_gas'])\n",
    "                            fast_int_to_gas = np.append(fast_int_to_gas, all_dens[q]['Nfint_to_gas'])\n",
    "\n",
    "                            bulk_lat_mean = np.append(bulk_lat_mean, all_pres_new4[s]['bulk_mean'])\n",
    "\n",
    "                            bub_width_arr = np.append(bub_width_arr, all_pres_new[t]['radius'][int(len(slow_gas_to_bulk)/2):])\n",
    "                            bub_surface_area_arr = np.append(bub_surface_area_arr, all_pres_new[t]['sa_ext'][int(len(slow_gas_to_bulk)/2):])\n",
    "                            int_width_arr = np.append(int_width_arr, all_pres_new[t]['edge_width'][int(len(slow_gas_to_bulk)/2):])\n",
    "\n",
    "                            slow_act = np.append(slow_act, params['peA'][q])\n",
    "                            fast_act = np.append(fast_act, params['peB'][q])\n",
    "\n",
    "\n",
    "\n",
    "                            gas_to_bulk_mean = np.append(gas_to_bulk_mean, np.mean(gas_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_gas_to_bulk_mean = np.append(slow_gas_to_bulk_mean, np.mean(slow_gas_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_gas_to_bulk_mean = np.append(fast_gas_to_bulk_mean, np.mean(fast_gas_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            bulk_to_gas_mean = np.append(bulk_to_gas_mean, np.mean(bulk_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_bulk_to_gas_mean = np.append(slow_bulk_to_gas_mean, np.mean(slow_bulk_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_bulk_to_gas_mean = np.append(fast_bulk_to_gas_mean, np.mean(fast_bulk_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            gas_to_int_mean = np.append(gas_to_int_mean, np.mean(gas_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_gas_to_int_mean = np.append(slow_gas_to_int_mean, np.mean(slow_gas_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_gas_to_int_mean = np.append(fast_gas_to_int_mean, np.mean(fast_gas_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            bulk_to_int_mean = np.append(bulk_to_int_mean, np.mean(bulk_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_bulk_to_int_mean = np.append(slow_bulk_to_int_mean, np.mean(slow_bulk_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_bulk_to_int_mean = np.append(fast_bulk_to_int_mean, np.mean(fast_bulk_to_int[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            int_to_bulk_mean = np.append(int_to_bulk_mean, np.mean(int_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_int_to_bulk_mean = np.append(slow_int_to_bulk_mean, np.mean(slow_int_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_int_to_bulk_mean = np.append(fast_int_to_bulk_mean, np.mean(fast_int_to_bulk[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            int_to_gas_mean = np.append(int_to_gas_mean, np.mean(int_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            slow_int_to_gas_mean = np.append(slow_int_to_gas_mean, np.mean(slow_int_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "                            fast_int_to_gas_mean = np.append(fast_int_to_gas_mean, np.mean(fast_int_to_gas[int(len(slow_gas_to_bulk)/2):]))\n",
    "\n",
    "                            bulk_lat_mean_mean = np.append(bulk_lat_mean_mean, np.mean(bulk_lat_mean))\n",
    "\n",
    "                            bulk_nA_mean = np.append(bulk_nA_mean, np.mean(bulk_nA_arr))\n",
    "                            bulk_nB_mean = np.append(bulk_nB_mean, np.mean(bulk_nB_arr))\n",
    "                            bulk_n_mean = np.append(bulk_n_mean, np.mean(bulk_n_arr))\n",
    "\n",
    "                            int_n_mean = np.append(int_n_mean, np.mean(int_n_arr))\n",
    "                            int_nA_mean = np.append(int_nA_mean, np.mean(int_nA_arr))\n",
    "                            int_nB_mean = np.append(int_nB_mean, np.mean(int_nB_arr))\n",
    "\n",
    "                            gas_n_mean = np.append(gas_n_mean, np.mean(gas_n_arr))\n",
    "                            gas_nA_mean = np.append(gas_nA_mean, np.mean(gas_nA_arr))\n",
    "                            gas_nB_mean = np.append(gas_nB_mean, np.mean(gas_nB_arr))\n",
    "\n",
    "                            dense_n_mean = np.append(dense_n_mean, np.mean(dense_n_arr))\n",
    "                            dense_nA_mean = np.append(dense_nA_mean, np.mean(dense_nA_arr))\n",
    "                            dense_nB_mean = np.append(dense_nB_mean, np.mean(dense_nB_arr))\n",
    "                            #print(bub_surface_area_mean)\n",
    "                            bub_width_mean = np.append(bub_width_mean, np.mean(bub_width_arr))\n",
    "                            bub_surface_area_mean = np.append(bub_surface_area_mean, np.mean(bub_surface_area_arr))\n",
    "                            int_width_mean = np.append(int_width_mean, np.mean(int_width_arr))\n",
    "\n",
    "\n",
    "                            adsorp_rate = np.append(adsorp_rate, bub_surface_area_mean[-1] * gas_n_mean[-1] * (slow_act[-1] * 0.5 + fast_act[-1] * 0.5) / np.pi)\n",
    "                            #desorp_rate = np.append(desorp_rat, \n",
    "                            fastCol = '#e31a1c'\n",
    "                            slowCol = '#081d58'\n",
    "                            print(params['peA'][q])\n",
    "                            print(params['peB'][q])\n",
    "                            fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "                            plot_max = np.max(gas_to_bulk)\n",
    "                            fsize=10\n",
    "\n",
    "\n",
    "\n",
    "                            plot_min = -0.1\n",
    "                            step = np.round(np.abs(plot_max - plot_min)/6,2)\n",
    "                            if step < 0:\n",
    "                                step = step * -1\n",
    "\n",
    "\n",
    "                            plt.plot(time, gas_to_bulk, label=r'all',\n",
    "                                           c='black', lw=1.8*1.8, ls='--')\n",
    "                            plt.plot(time, slow_gas_to_bulk, label=r'Slow',\n",
    "                                           c=slowCol, lw=1.8*1.8, ls='--')\n",
    "                            plt.plot(time, fast_gas_to_bulk, label=r'Fast',\n",
    "                                           c=fastCol, lw=1.8*1.8, ls='--')\n",
    "\n",
    "\n",
    "                            ax1.set_ylim(plot_min, plot_max)\n",
    "                            #ax1.set_xlim(0, 1.4)\n",
    "\n",
    "\n",
    "                            ax1.set_xlabel(r'Time ($\\tau_\\mathrm{B}$)', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "\n",
    "                            ax1.set_ylabel(r'Rate of Penetration', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "                            # Set all the x ticks for radial plots\n",
    "                            loc = ticker.MultipleLocator(base=50)\n",
    "                            ax1.xaxis.set_major_locator(loc)\n",
    "                            loc = ticker.MultipleLocator(base=25)\n",
    "                            ax1.xaxis.set_minor_locator(loc)\n",
    "                            plt.legend(loc='upper right', fontsize=fsize*2.6)\n",
    "\n",
    "\n",
    "                            # Set y ticks\n",
    "                            print(step)\n",
    "                            loc = ticker.MultipleLocator(base=step)\n",
    "                            ax1.yaxis.set_major_locator(loc)\n",
    "                            loc = ticker.MultipleLocator(base=round(step/2,3))\n",
    "                            ax1.yaxis.set_minor_locator(loc)\n",
    "                            # Left middle plot\n",
    "                            ax1.tick_params(axis='x', labelsize=fsize*2.5)\n",
    "                            ax1.tick_params(axis='y', labelsize=fsize*2.5)\n",
    "                            #plt.legend(loc='upper right')\n",
    "\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n",
    "                            \n",
    "                            fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "                            plot_max = np.max(bulk_to_gas)\n",
    "                            fsize=10\n",
    "\n",
    "\n",
    "\n",
    "                            plot_min = -0.1\n",
    "                            step = np.round(np.abs(plot_max - plot_min)/6,2)\n",
    "                            if step < 0:\n",
    "                                step = step * -1\n",
    "\n",
    "\n",
    "                            plt.plot(time, bulk_to_gas, label=r'all',\n",
    "                                           c='black', lw=1.8*1.8, ls='--')\n",
    "                            plt.plot(time, slow_bulk_to_gas, label=r'Slow',\n",
    "                                           c=slowCol, lw=1.8*1.8, ls='--')\n",
    "                            plt.plot(time, fast_bulk_to_gas, label=r'Fast',\n",
    "                                           c=fastCol, lw=1.8*1.8, ls='--')\n",
    "\n",
    "\n",
    "                            ax1.set_ylim(plot_min, plot_max)\n",
    "                            #ax1.set_xlim(0, 1.4)\n",
    "\n",
    "\n",
    "                            ax1.set_xlabel(r'Time ($\\tau_\\mathrm{B}$)', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "\n",
    "                            ax1.set_ylabel(r'Rate of Exiting Bulk', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "                            # Set all the x ticks for radial plots\n",
    "                            loc = ticker.MultipleLocator(base=50)\n",
    "                            ax1.xaxis.set_major_locator(loc)\n",
    "                            loc = ticker.MultipleLocator(base=25)\n",
    "                            ax1.xaxis.set_minor_locator(loc)\n",
    "                            plt.legend(loc='upper right', fontsize=fsize*2.6)\n",
    "\n",
    "\n",
    "                            # Set y ticks\n",
    "                            print(step)\n",
    "                            loc = ticker.MultipleLocator(base=step)\n",
    "                            ax1.yaxis.set_major_locator(loc)\n",
    "                            loc = ticker.MultipleLocator(base=round(step/2,3))\n",
    "                            ax1.yaxis.set_minor_locator(loc)\n",
    "                            # Left middle plot\n",
    "                            ax1.tick_params(axis='x', labelsize=fsize*2.5)\n",
    "                            ax1.tick_params(axis='y', labelsize=fsize*2.5)\n",
    "                            #plt.legend(loc='upper right')\n",
    "\n",
    "                            plt.tight_layout()\n",
    "                            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(slow_act * 0.5 + fast_act * 0.5, gas_to_int_mean)\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, adsorp_rate)\n",
    "plt.show()\n",
    "print(bub_surface_area_mean)\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, gas_to_int_mean/(time[1]-time[0]))\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, gas_to_bulk_mean/(time[1]-time[0]))\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, slow_gas_to_bulk_mean/(time[1]-time[0]))\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, fast_gas_to_bulk_mean/(time[1]-time[0]))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, bulk_to_gas_mean/(time[1]-time[0]))\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, slow_bulk_to_gas_mean/(time[1]-time[0]))\n",
    "plt.scatter(slow_act * 0.5 + fast_act * 0.5, fast_bulk_to_gas_mean/(time[1]-time[0]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
