{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the import cell\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import matplotlib.ticker as ticker\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import pylab as plot\n",
    "first = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "\n",
    "\n",
    "# Here are my rc parameters for matplotlibf\n",
    "fsize = 20\n",
    "mpl.rc('font', serif='Helvetica Neue')\n",
    "#mpl.rc('font', serif='Times New Roman')\n",
    "mpl.rcParams.update({'font.size': fsize})\n",
    "mpl.rcParams['figure.figsize'] = 3.2, 2.8\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "# Set x tick params\n",
    "mpl.rcParams['xtick.major.size'] = 4.5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['xtick.minor.size'] = 3.\n",
    "mpl.rcParams['xtick.minor.width'] = 1.25\n",
    "# Set y tick params\n",
    "mpl.rcParams['ytick.major.size'] = 4.5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.minor.size'] = 3.\n",
    "mpl.rcParams['ytick.minor.width'] = 1.25\n",
    "mpl.rcParams['legend.fontsize']= 20.\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Load LaTeX and amsmath\n",
    "# mpl.rc('text', usetex=True)\n",
    "# mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current path\n",
    "if first:\n",
    "    parent = os.getcwd()\n",
    "print(parent)\n",
    "# Grab file names from data folder\n",
    "dens = os.listdir('../../../../txt_files/fast_out_txt_files/Align_press_CoM')\n",
    "try:\n",
    "    data.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres = os.listdir('../../../../txt_files/fast_out_txt_files/Interpart_press')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres2 = os.listdir('../../../../txt_files/fast_out_txt_files/BubComp')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to get the relevant data from the filenames\n",
    "def checkFile(fname, string):\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "#             print\"{} matches {}\".format(fname[i], string[0])\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "#                     print\"{} matches {}\".format(fname[i+j], string[j])\n",
    "                    if j == (len(string) - 1):\n",
    "#                         print\"Final match!\"\n",
    "                        return True\n",
    "                else:\n",
    "                    break\n",
    "    return False\n",
    "    \n",
    "def txtValue(fname, string):\n",
    "    out = \"\"\n",
    "    index = 0\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "                    if j == (len(string) - 1):\n",
    "                        # Last index of search string\n",
    "                        index = i + j\n",
    "                else:\n",
    "                    break\n",
    "                        \n",
    "    # First index of value\n",
    "    index += 1\n",
    "    mybool = True\n",
    "    while mybool:\n",
    "        if fname[index].isdigit():\n",
    "            out = out + fname[index]\n",
    "            index += 1\n",
    "        elif fname[index] == \".\":    \n",
    "            if fname[index+1].isdigit():\n",
    "                out = out + fname[index]\n",
    "                index += 1\n",
    "            else:\n",
    "                mybool = False\n",
    "        else:\n",
    "            mybool = False\n",
    "    return float(out)\n",
    "\n",
    "# Sorting functions\n",
    "def multiSort(arr1, arr2, arr3, arr4):\n",
    "    \"\"\"Sort an array the slow (but certain) way, returns original indices in sorted order\"\"\"\n",
    "    # Doing this for PeR, PeS, xS in this case\n",
    "    cpy1 = np.copy(arr1)\n",
    "    cpy2 = np.copy(arr2)\n",
    "    cpy3 = np.copy(arr3)\n",
    "    cpy4 = np.copy(arr4)\n",
    "    ind = np.arange(0, len(arr1))\n",
    "    for i in range(len(cpy1)):\n",
    "        for j in range(len(cpy1)):\n",
    "            # Sort by first variable\n",
    "            if cpy1[i] > cpy1[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            # If first variable is equal, resort to second variable\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] > cpy2[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] > cpy3[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] == cpy3[j] and cpy4[i] > cpy4[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def indSort(arr1, arr2):\n",
    "    \"\"\"Take sorted index array, use to sort array\"\"\"\n",
    "    # arr1 is array to sort\n",
    "    # arr2 is index array\n",
    "    cpy = np.copy(arr1)\n",
    "    for i in range(len(arr1)):\n",
    "        arr1[i] = cpy[arr2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in dens:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "                \n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(dens, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_dens = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../txt_files/fast_out_txt_files/Align_press_CoM')\n",
    "for i in dens:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_dens.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_dens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_dens)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params = params.append(df, ignore_index = True)\n",
    "display(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_dens)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_dens[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_dens[0])\n",
    "display(all_dens[0])\n",
    "print(all_dens[0][headers[1]][0])\n",
    "print(all_dens[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../txt_files/fast_out_txt_files/Interpart_press')\n",
    "for i in pres:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params2 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params2 = params2.append(df, ignore_index = True)\n",
    "display(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres[0])\n",
    "display(all_pres[0])\n",
    "print(all_pres[0][headers[1]][0])\n",
    "print(all_pres[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres2:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres2, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../txt_files/fast_out_txt_files/BubComp')\n",
    "for i in pres2:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params3 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params3 = params3.append(df, ignore_index = True)\n",
    "display(params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new[0])\n",
    "display(all_pres_new[0])\n",
    "print(all_pres_new[0][headers[1]][0])\n",
    "print(all_pres_new[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data is loaded, now compute analytical aspects\n",
    "r_cut = (2.**(1./6.))\n",
    "\n",
    "# Get lattice spacing for particle size\n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / sigma) * ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "# # Lennard-Jones pressure\n",
    "# def ljPress(r, eps, sigma=1.):\n",
    "#     phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "#     div = (sigma/r)\n",
    "#     dU = (24. * eps / r) * ((2.*(div**12.)) - (div)**6.)\n",
    "#     # This is just pressure divided by the area of a particle\n",
    "# #     return (12. * dU / (np.pi * r))\n",
    "#     return (12. * dU / (np.pi * r * phiCP))\n",
    "\n",
    "def ljPress(r, pe, eps, sigma=1.):\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    # This is off by a factor of 1.2...\n",
    "    ljF = avgCollisionForce(pe)\n",
    "    return (2. *np.sqrt(3) * ljF / r)\n",
    "    \n",
    "def avgCollisionForce(pe, power=1.):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    peCritical = 40.\n",
    "    if pe < peCritical:\n",
    "        pe = 0\n",
    "    else:\n",
    "        pe -= peCritical\n",
    "    magnitude = 6.\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "#     return (magnitude * (pe**power)) / (np.pi)\n",
    "#     return (pe * (1. + (8./(np.pi**2.))))\n",
    "    coeff = 1.92#2.03#3.5#2.03\n",
    "    #coeff= 0.4053\n",
    "    return (pe * coeff)\n",
    "\n",
    "def fStar(pe, epsilon, sigma=1.):\n",
    "    out = (avgCollisionForce(pe) * sigma) / (24.*epsilon)\n",
    "    return out\n",
    "    \n",
    "def conForRClust(pe, eps):\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(pe):\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "\n",
    "def nonDimFLJ(r, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "def latForFStar(fstar):\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while nonDimFLJ(r) < fstar:\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "    \n",
    "def latToPhi(latIn):\n",
    "    '''Read in lattice spacing, output phi'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "\n",
    "# From area fraction, get lattice spacing\n",
    "def phiToLat(phiIn):\n",
    "    '''Read in phi, output the lattice spacing'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    latCP = 1.\n",
    "    return np.sqrt(phiCP / phiIn)\n",
    "    \n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    return num / den\n",
    "    \n",
    "def clustFrac(phi, phiG, a, sig=1.):\n",
    "    phiL = latToPhi(a)\n",
    "    ApL = np.pi * (sig**2) / 4.\n",
    "    Ap = np.pi * (sig**2) / 4.\n",
    "    num = (phiL*phiG) - (phiL*phi)\n",
    "    den = (phi*phiG) - (phi*phiL)\n",
    "    ans = num / den\n",
    "    return ans\n",
    "\n",
    "def radCurve(area):\n",
    "    # From area of circle get curvature\n",
    "    return np.sqrt(area/np.pi)\n",
    "\n",
    "def radCirc(circ):\n",
    "    return circ / (2. * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "kT = 1.0                        # temperature\n",
    "threeEtaPiSigma = 1.0           # drag coefficient\n",
    "sigma = 1.0                     # particle diameter\n",
    "D_t = kT / threeEtaPiSigma      # translational diffusion constant\n",
    "D_r = (3.0 * D_t) / (sigma**2)  # rotational diffusion constant\n",
    "tauBrown = (sigma**2) / D_t     # brownian time scale (invariant)\n",
    "\n",
    "\n",
    "\n",
    "def compPeNet(xf, pes, pef):\n",
    "    \"Given each species activity (pes and pef) and particle fraction (xf), compute net activity (peNet)\"\n",
    "    peNet = (pes * (1.-xf)) + (pef * xf)\n",
    "    return peNet\n",
    "def avgCollisionForce(peNet):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "    return (magnitude * peNet) / (np.pi)  \n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    '''Compute the Lennard-Jones force'''\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / r) * ((2*(div**12)) - (div)**6)\n",
    "    return dU\n",
    "\n",
    "# Lennard-Jones pressure\n",
    "def ljPress(r, pe, eps, sigma=1.):\n",
    "    '''\n",
    "    Purpose: Take epsilon (magnitude of lennard-jones force), sigma (particle diameter),\n",
    "    activity (pe), and separation distance (r) of 2 particles to compute pressure from\n",
    "    avg compressive active forces from neighbors\n",
    "    \n",
    "    Inputs: \n",
    "        r: Separation distance in simulation units\n",
    "        epsilon: magnitude of lennard-jones potential\n",
    "        pe: activity (peclet number)\n",
    "        sigma: particle diameter (default=1.0)\n",
    "    \n",
    "    Output: Analytical virial pressure (see monodisperse paper for derivation)\n",
    "    '''\n",
    "    #Area fraction at HCP\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    \n",
    "    # LJ force\n",
    "    ljF = avgCollisionForce(pe)\n",
    "    \n",
    "    return (2. *np.sqrt(3) * ljF / r)\n",
    "\n",
    "def getLat(peNet, eps):\n",
    "    '''Get the lattice spacing for any pe'''\n",
    "    if peNet == 0:\n",
    "        return 2.**(1./6.)\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(peNet):\n",
    "            r -= j\n",
    "        r += j\n",
    "    return r  \n",
    "def latToPhi(latIn):\n",
    "    '''Read in lattice spacing, output phi'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "\n",
    "#Calculate gas phase area fraction\n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    '''\n",
    "    Purpose: Compute analytical area fraction of the gas phase at steady state\n",
    "    given activity and lattice spacing\n",
    "    \n",
    "    Inputs: \n",
    "        pe: net activity (peclet number)\n",
    "        a: lattice spacing \n",
    "        kap: fitting parameter (default=4.5, shown by Redner)\n",
    "        sig: particle diameter (default=1.0)\n",
    "    \n",
    "    Output: Area fraction of the gas phase at steady state\n",
    "    '''\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    if den>0:\n",
    "        return num / den\n",
    "    else:\n",
    "        return 0\n",
    "# Calculate dense phase area fraction from lattice spacing\n",
    "def latToPhi(latIn):\n",
    "    '''\n",
    "    Purpose: Compute analytical area fraction of the dense phase given the lattice\n",
    "    spacing.\n",
    "    \n",
    "    Inputs: \n",
    "        latIn: lattice spacing\n",
    "    \n",
    "    Output: dense phase area fraction\n",
    "    '''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "def areaType(Nx, latx):\n",
    "    Ax = Nx * np.pi * 0.25 * (latx**2)\n",
    "    return Ax\n",
    "\n",
    "#Slow activities interested in\n",
    "pe_a = [0, 100, 150, 200, 250, 350, 450]\n",
    "#Fast activities interested in\n",
    "pe_b = [0, 100, 150, 200, 250, 350, 450]\n",
    "\n",
    "#Particle fraction of slow activities\n",
    "xA = 50./100.0\n",
    "\n",
    "#Particle fraction of fast activities\n",
    "xF = 50./100.0\n",
    "\n",
    "#Particle fraction of slow activities\n",
    "xS=1.0-xF\n",
    "\n",
    "partNum = 50000          # total number of particles\n",
    "partNumS=xS*partNum      # total number of slow particles\n",
    "partNumF=xF*partNum      # total number of fast particles\n",
    "\n",
    "intPhi = 60               # integer system area fraction\n",
    "phi = float(intPhi)/100.0 # system area fraction\n",
    "eps = 1.0                 # particle softness\n",
    "\n",
    "#initialize empty arrays for appending to\n",
    "press_fast_int = np.array([])\n",
    "press_slow_int = np.array([])\n",
    "press_fast_dense = np.array([])\n",
    "press_slow_dense = np.array([])\n",
    "pa_pair = np.array([])\n",
    "pb_pair = np.array([])\n",
    "pnet_pair = np.array([])\n",
    "int_width_slow = np.array([])\n",
    "int_width_fast = np.array([])\n",
    "int_width_theory = np.array([])\n",
    "int_width_predict_fastd = np.array([])\n",
    "int_width_predict_slowd = np.array([])\n",
    "int_width_fast_int_arr = np.array([])\n",
    "int_width_slow_int_arr = np.array([])\n",
    "#Loop over slow activities\n",
    "for i in range(0, len(pe_a)): \n",
    "    \n",
    "    #Loop over fast activities\n",
    "    for j in range(0, len(pe_b)):\n",
    "        \n",
    "        #Be sure slow activity is less than or equal to fast activity\n",
    "        if pe_a[i]<=pe_b[j]:\n",
    "            \n",
    "            #Compute net activity\n",
    "            peNet = compPeNet(xF, pe_a[i], pe_b[j])\n",
    "            \n",
    "            # Compute lattice spacing based on each activity\n",
    "            latS = getLat(pe_a[i], eps)\n",
    "            latF = getLat(pe_b[j], eps)\n",
    "            latNet = getLat(peNet, eps)\n",
    "            \n",
    "            Ns = partNum * (1. - xF)          # number of slow particles\n",
    "            Nf = partNum - Ns                 # number of fast particles\n",
    "            \n",
    "            phiG = compPhiG(peNet, latNet)              # area fraction of gas phase\n",
    "            NGas = (phiG / phi) * partNum    # number of gas particles\n",
    "            \n",
    "            #Compute area fraction of dense phase based on each lattice spacing\n",
    "            phi_theory = latToPhi(latNet)\n",
    "            phiS_theory = latToPhi(latS)\n",
    "            phiF_theory = latToPhi(latF)\n",
    "            \n",
    "            #Compute number density of slow and fast particles\n",
    "            nS_theory = phi_theory /(np.pi/4)\n",
    "            nF_theory = phi_theory /(np.pi/4)\n",
    "            \n",
    "            #Compute number of particles in liquid phase\n",
    "            Nl = int(round(partNum * ((phi_theory * (phiG - phi)) / (phi * (phiG - phi_theory)))))\n",
    "            \n",
    "            #Compute number of particles in gas phase\n",
    "            NGas = partNum - Nl\n",
    "            \n",
    "            # Critical packing fraction in HCP lattice\n",
    "            phiCP = np.pi / (2. * np.sqrt(3))\n",
    "            \n",
    "            # The area is the sum of the particle areas (normalized by close packing density of spheres)\n",
    "            Al = (Nl * np.pi * (latNet)**2) / (4*phiCP)\n",
    "            As = (Ns * np.pi * (latNet)**2) / (4*phiCP)\n",
    "            if As > Al:\n",
    "                As = Al\n",
    "            Af = (Nf * np.pi * (latNet)**2) / (4*phiCP)\n",
    "            if Af > Al:\n",
    "                Af = Al\n",
    "            \n",
    "            # The area for instantiated liquid cluster\n",
    "            Al_real=Al\n",
    "            \n",
    "            # The cluster radius is the square root of liquid area divided by pi\n",
    "            Rl = np.sqrt(Al_real / np.pi)\n",
    "            Rs = np.sqrt(As / np.pi)\n",
    "            Rf = np.sqrt(Af / np.pi)\n",
    "            \n",
    "            #The interface width is the difference between the 100% bulk species radius and the total cluster radius\n",
    "            int_width_fast_int = Rl-Rs\n",
    "            int_width_slow_int = Rl-Rf\n",
    "            int_width_fast_int_arr = np.append(int_width_fast_int_arr, int_width_fast_int)\n",
    "            int_width_slow_int_arr = np.append(int_width_slow_int_arr, int_width_slow_int)\n",
    "            #Calculate interface aligned active pressure from theory\n",
    "            press_fast_int = np.append(press_fast_int, int_width_fast_int * nF_theory * 1.0 * pe_b[j])\n",
    "            press_slow_int = np.append(press_slow_int, int_width_slow_int * nS_theory * 1.0 * pe_a[i])\n",
    "            \n",
    "            #Calculate bulk interparticle pressure from theory\n",
    "            press_slow_dense_val = 4.0 * np.sqrt(3) * peNet / latNet\n",
    "            press_fast_dense_val = 4.0 * np.sqrt(3) * peNet / latNet\n",
    "            \n",
    "            #Append pressures to array\n",
    "            press_slow_dense = np.append(press_slow_dense, press_slow_dense_val)\n",
    "            press_fast_dense = np.append(press_fast_dense, press_fast_dense_val)\n",
    "            int_width_predict_slowd = np.append(int_width_predict_slowd, press_slow_dense_val/(pe_b[j]*nF_theory))\n",
    "            int_width_predict_fastd = np.append(int_width_predict_fastd, press_fast_dense_val/(pe_a[i]*nS_theory))\n",
    "            \n",
    "            #Append activities to array\n",
    "            pa_pair = np.append(pa_pair, pe_a[i])\n",
    "            pb_pair = np.append(pb_pair, pe_b[j])\n",
    "            pnet_pair = np.append(pnet_pair, pe_b[j]*0.5 + pe_a[i]*0.5)\n",
    "            \n",
    "            #Append interface widths to array\n",
    "            int_width_fast = np.append(int_width_fast, int_width_fast_int)\n",
    "            int_width_slow = np.append(int_width_slow, int_width_slow_int)\n",
    "            \n",
    "            #Calculate dense phase pressure again and constants for predicting what interface width is for balancing pressure\n",
    "            curPLJ = ljPress(latNet, peNet, eps)\n",
    "\n",
    "            alpha_max = 0.5\n",
    "            I_arr = 3.0\n",
    "            int_width = (np.sqrt(3)/(2*alpha_max)) * (curPLJ/peNet) * (latNet **2) * I_arr\n",
    "            int_width_theory = np.append(int_width_theory, int_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use analytical theory and kinetic theory to get cluster radius\n",
    "epsRange = [1., 0.1, 0.01, 0.001, 0.0001]\n",
    "# epsRange = [0.0001, 0.001, 0.01, 0.1, 1.]\n",
    "peRange = np.arange(0., 700., 1.)\n",
    "phiRange = [0.45, 0.55, 0.65]\n",
    "N = 100000.\n",
    "norm = 10.**0.\n",
    "# norm = 1.\n",
    "\n",
    "phiCP = np.pi / (2. * np.sqrt(3))\n",
    "lat = []\n",
    "pColl = []\n",
    "pLJ = []\n",
    "cfs = []\n",
    "Rls = []\n",
    "peCrit = []\n",
    "phiGs = []\n",
    "phiCPs = []\n",
    "a_box = []\n",
    "l_box = []\n",
    "for b in range(0, len(phiRange)):\n",
    "    lat.append([])\n",
    "    phiCPs.append([])\n",
    "    pColl.append([])\n",
    "    pLJ.append([])\n",
    "    cfs.append([])\n",
    "    Rls.append([])\n",
    "    phiGs.append([])\n",
    "    peCrit.append([])\n",
    "    a_box.append(N * np.pi * 0.25 / phiRange[b])\n",
    "    l_box.append(np.sqrt(a_box[-1]))\n",
    "    for i in range(0, len(epsRange)):\n",
    "        lat[b].append([])\n",
    "        phiCPs[b].append([])\n",
    "        pColl[b].append([])\n",
    "        pLJ[b].append([])\n",
    "        cfs[b].append([])\n",
    "        Rls[b].append([])\n",
    "        phiGs[b].append([])\n",
    "        for j in range(0, len(peRange)):\n",
    "            # Compute lattice spacing\n",
    "        \n",
    "            lat[b][i].append(conForRClust(peRange[j], epsRange[i]))\n",
    "            phiCPs[b][i].append(latToPhi(lat[b][i][-1]))\n",
    "            # Compute pressure\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP)\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP * (lat[b][i][-1]**(0.5)) * 1.25)\n",
    "            curPLJ = ljPress(lat[b][i][-1], peRange[j], epsRange[i])\n",
    "            \n",
    "            # Append to list\n",
    "            pLJ[b][i].append(curPLJ/(norm))\n",
    "\n",
    "            # Compute cluster fraction\n",
    "            phiG = compPhiG(peRange[j], lat[b][i][-1])\n",
    "            phiGs[b][i].append(phiG)\n",
    "            if peRange[j] > 35.:\n",
    "                cf = clustFrac(phiRange[b], phiG, lat[b][i][-1])\n",
    "                if cf < 0. or cf > 1.:\n",
    "                    cf = 0.\n",
    "            else:\n",
    "                cf = 0\n",
    "            cfs[b][i].append(cf)\n",
    "\n",
    "            # Get the critical activity\n",
    "            if j > 0:\n",
    "                if cfs[b][i][-2] == 0. and cfs[b][i][-1] > 0.:\n",
    "                    peCrit[b].append(peRange[j])\n",
    "\n",
    "            # Get the radius (for some N)\n",
    "            Nl = cfs[b][i][-1] * N\n",
    "            Al = Nl * ((np.pi * (lat[b][i][-1]**2))/(4*phiCP))\n",
    "            Rl = np.sqrt(Al / (np.pi))\n",
    "            Rls[b][i].append(Rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "\n",
    "for i in range(0, len(all_dens)):\n",
    "    align_press_total = 0\n",
    "    align_press_vals=0\n",
    "    \n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_dens[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_dens[i]['clust_size'])\n",
    "    for j in range(0, len(all_dens[i]['clust_size'])):\n",
    "        #if all_dens[i]['clust_size'][j]>=0.95*max_size:\n",
    "            align_press = all_dens[i]['press_align'][j]\n",
    "            if align_press > 0:\n",
    "                align_press_total += align_press\n",
    "                align_press_vals += 1\n",
    "    if align_press_vals > 50:        \n",
    "        avg_press = (align_press_total/align_press_vals)\n",
    "        align_press_arr = np.append(align_press_arr, avg_press)\n",
    "        align_peA=np.append(align_peA, params['peA'][i])\n",
    "        align_peB=np.append(align_peB, params['peB'][i])\n",
    "        align_peNet=np.append(align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "        align_xA=np.append(align_xA, params['xA'][i])\n",
    "        align_phi=np.append(align_phi, params['phi'][i])\n",
    "        align_eps=np.append(align_eps, params['eps'][i])\n",
    "\n",
    "    \n",
    "interpart_peA=np.array([])\n",
    "interpart_peB=np.array([])\n",
    "interpart_peNet=np.array([])\n",
    "interpart_xA=np.array([])\n",
    "interpart_eps=np.array([])\n",
    "interpart_pnum=np.array([])\n",
    "interpart_phi=np.array([])\n",
    "interpart_press=np.array([])\n",
    "interpart_press_expand=np.array([])\n",
    "avg_shear=np.array([])\n",
    "for i in range(0, len(all_pres)):\n",
    "    bulk_press_total = 0\n",
    "    bulk_press_total_expand = 0\n",
    "    bulk_press_vals=0\n",
    "    shear_press_expand=0\n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_pres[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_pres[i]['NDense'])\n",
    "    for j in range(0, len(all_pres[i]['NDense'])):\n",
    "        #if all_pres[i]['NDense'][j]>=0.95*max_size:\n",
    "        \n",
    "            bulk_trace = (all_pres[i]['bulkSigXX'].iloc[j]+all_pres[i]['bulkSigYY'].iloc[j])/2#+all_pres_new[i]['bulkSigYX'].iloc[-1]+all_pres_new[i]['bulkSigYY'].iloc[-1])/2\n",
    "            bulk_press = bulk_trace / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            \n",
    "            bulk_trace_expand = (all_pres[i]['bulkSigXX'].iloc[j]+all_pres[i]['bulkSigXY'].iloc[j]+all_pres[i]['bulkSigYX'].iloc[j]+all_pres[i]['bulkSigYY'].iloc[j])/2\n",
    "            bulk_press_expand = bulk_trace_expand / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            \n",
    "            shear_stress = (all_pres[i]['bulkSigXY'].iloc[j]+all_pres[i]['bulkSigYX'].iloc[j])/2\n",
    "            shear_press = shear_stress / (all_pres[i]['bulkArea'].iloc[j])\n",
    "            if bulk_press > 0:\n",
    "                shear_press_expand +=shear_press\n",
    "                bulk_press_total += bulk_press\n",
    "                bulk_press_total_expand += bulk_press_expand\n",
    "                bulk_press_vals += 1\n",
    "    if bulk_press_vals > 50:        \n",
    "        avg_shear = np.append(avg_shear, shear_press_expand/bulk_press_vals)\n",
    "        avg_press = (bulk_press_total/(2*bulk_press_vals))\n",
    "        avg_press_expand = (bulk_press_total_expand/bulk_press_vals)\n",
    "        interpart_press=np.append(interpart_press, avg_press)\n",
    "        interpart_press_expand=np.append(interpart_press_expand, avg_press_expand)\n",
    "        interpart_peA=np.append(interpart_peA, params2['peA'][i])\n",
    "        interpart_peB=np.append(interpart_peB, params2['peB'][i])\n",
    "        interpart_peNet=np.append(interpart_peNet, params2['peB'][i] * (1-params2['xA'][i]/100) + params2['peA'][i] * (params2['xA'][i]/100))\n",
    "        interpart_xA=np.append(interpart_xA, params2['xA'][i])\n",
    "        interpart_phi=np.append(interpart_phi, params2['phi'][i])\n",
    "        interpart_eps=np.append(interpart_eps, params2['eps'][i])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(interpart_peNet, interpart_press, c='blue', label='bulk interparticle')\n",
    "plt.scatter(align_peNet, align_press_arr, c='red', label='aligned interface')\n",
    "plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "'''\n",
    "for i in range(0, len(align_peA)):  \n",
    "    for j in range(0, len(align_peB)):  \n",
    "        for k in range(0, len(interpart_peA)):  \n",
    "            for l in range(0, len(interpart_peB)):  \n",
    "                if (align_peA[i]==interpart_peA[k]) & (align_peB[j]==interpart_peB[l]):\n",
    "                    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "first_align_peNet=np.array([])\n",
    "first_interpart_peNet=np.array([])\n",
    "first_interpart_peA=np.array([])\n",
    "first_interpart_peB=np.array([])\n",
    "\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "first_align_press = np.array([])\n",
    "first_bulk_press = np.array([])\n",
    "first_align_peA=np.array([])\n",
    "first_align_peB=np.array([])\n",
    "\n",
    "interpart_peA=np.array([])\n",
    "interpart_peB=np.array([])\n",
    "interpart_peNet=np.array([])\n",
    "interpart_xA=np.array([])\n",
    "interpart_eps=np.array([])\n",
    "interpart_pnum=np.array([])\n",
    "interpart_phi=np.array([])\n",
    "interpart_press=np.array([])\n",
    "interpart_press_expand=np.array([])\n",
    "avg_shear=np.array([])\n",
    "fastCol = '#e31a1c'\n",
    "slowCol = '#081d58'\n",
    "\n",
    "for i in range(0, len(all_dens)):\n",
    "    \n",
    "    align_time =np.array([])\n",
    "    align_press_time = np.array([])\n",
    "    align_press_total = 0\n",
    "    align_press_vals=0\n",
    "    \n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_dens[i].empty:\n",
    "            continue\n",
    "    \n",
    "    largest_bubble = np.array([])\n",
    "    second_largest_bubble = np.array([])\n",
    "    third_largest_bubble = np.array([])\n",
    "    fourth_largest_bubble = np.array([])\n",
    "    fifth_largest_bubble = np.array([])\n",
    "    tot_time_arr = np.array([])\n",
    "    max_size = np.amax(all_dens[i]['clust_size'])\n",
    "    for j in range(0, len(all_dens[i]['clust_size'])):\n",
    "        #if all_dens[i]['clust_size'][j]>=0.95*max_size:\n",
    "            tot_time_arr = np.append(tot_time_arr, all_dens[i]['tauB'][j])\n",
    "\n",
    "            align_press = all_dens[i]['press_align'][j]\n",
    "            \n",
    "            if j==0:\n",
    "                first_align_press = np.append(first_align_press, align_press)\n",
    "                first_align_peNet=np.append(first_align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "                first_align_peA=np.append(first_align_peA, params['peA'][i])\n",
    "                first_align_peB=np.append(first_align_peB, params['peB'][i])\n",
    "                \n",
    "            if align_press > 0:\n",
    "                align_time = np.append(align_time, all_dens[i]['tauB'].iloc[j])\n",
    "                align_press_time = np.append(align_press_time, align_press)\n",
    "            \n",
    "                align_press_total += align_press\n",
    "                align_press_vals += 1\n",
    "    if align_press_vals > 50:        \n",
    "        avg_press = (align_press_total/align_press_vals)\n",
    "        align_press_arr = np.append(align_press_arr, avg_press)\n",
    "        align_peA=np.append(align_peA, params['peA'][i])\n",
    "        align_peB=np.append(align_peB, params['peB'][i])\n",
    "        align_peNet=np.append(align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "        align_xA=np.append(align_xA, params['xA'][i])\n",
    "        align_phi=np.append(align_phi, params['phi'][i])\n",
    "        align_eps=np.append(align_eps, params['eps'][i])\n",
    "    for k in range(0, len(all_pres)):\n",
    "        if params2['peA'][k]==params['peA'][i]:\n",
    "            if params2['peB'][k]==params['peB'][i]:\n",
    "                if params2['eps'][k]==params['eps'][i]:\n",
    "                    if params2['phi'][k]==params['phi'][i]:\n",
    "                        if params2['xA'][k]==params['xA'][i]:\n",
    "                            bulk_time =np.array([])\n",
    "                            bulk_press_time = np.array([])\n",
    "                            bulk_press_total = 0\n",
    "                            bulk_press_total_expand = 0\n",
    "                            bulk_press_vals=0\n",
    "                            shear_press_expand=0\n",
    "                            # Don't plot non-phase-separated data\n",
    "                            if all_pres[k].empty:\n",
    "                                    continue\n",
    "\n",
    "\n",
    "                            max_size = np.amax(all_pres[k]['NDense'])\n",
    "                            for l in range(0, len(all_pres[k]['NDense'])):\n",
    "                                \n",
    "                                    \n",
    "                                #if all_pres[i]['NDense'][j]>=0.95*max_size:\n",
    "\n",
    "                                bulk_trace = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2#+all_pres_new[i]['bulkSigYX'].iloc[-1]+all_pres_new[i]['bulkSigYY'].iloc[-1])/2\n",
    "                                bulk_press = bulk_trace / (all_pres[k]['bulkArea'].iloc[l])\n",
    "\n",
    "                                bulk_trace_expand = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2\n",
    "                                bulk_press_expand = bulk_trace_expand / (all_pres[k]['bulkArea'].iloc[l])\n",
    "                                if l == 0:\n",
    "                                    first_bulk_press = np.append(first_bulk_press, bulk_press)\n",
    "                                    first_interpart_peNet=np.append(first_interpart_peNet, params2['peB'][k] * (1-params2['xA'][k]/100) + params2['peA'][k] * (params2['xA'][k]/100))\n",
    "                                    first_interpart_peA=np.append(first_interpart_peA, params2['peA'][k])\n",
    "                                    first_interpart_peB=np.append(first_interpart_peB, params2['peB'][k])\n",
    "                                    \n",
    "                                shear_stress = (all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l])/2\n",
    "                                shear_press = shear_stress / (all_pres[k]['bulkArea'].iloc[l])\n",
    "                                if bulk_press>0:\n",
    "                                    bulk_time = np.append(bulk_time, all_pres[k]['Timestep'].iloc[l])\n",
    "                                    bulk_press_time = np.append(bulk_press_time, bulk_press/2)\n",
    "                                    shear_press_expand +=shear_press\n",
    "                                    bulk_press_total += bulk_press\n",
    "                                    bulk_press_total_expand += bulk_press_expand\n",
    "                                    bulk_press_vals += 1\n",
    "                            if bulk_press_vals > 50:        \n",
    "                                avg_shear = np.append(avg_shear, shear_press_expand/bulk_press_vals)\n",
    "                                avg_press = (bulk_press_total/(2*bulk_press_vals))\n",
    "                                avg_press_expand = (bulk_press_total_expand/bulk_press_vals)\n",
    "                                interpart_press=np.append(interpart_press, avg_press)\n",
    "                                interpart_press_expand=np.append(interpart_press_expand, avg_press_expand)\n",
    "                                interpart_peA=np.append(interpart_peA, params2['peA'][k])\n",
    "                                interpart_peB=np.append(interpart_peB, params2['peB'][k])\n",
    "                                interpart_peNet=np.append(interpart_peNet, params2['peB'][k] * (1-params2['xA'][k]/100) + params2['peA'][k] * (params2['xA'][k]/100))\n",
    "                                interpart_xA=np.append(interpart_xA, params2['xA'][k])\n",
    "                                interpart_phi=np.append(interpart_phi, params2['phi'][k])\n",
    "                                interpart_eps=np.append(interpart_eps, params2['eps'][k])\n",
    "                            if params2['peA'][k]==200:\n",
    "                                if params2['peB'][k]==450:\n",
    "                                    x_range_int = np.array([0.7, 0.7+0.0000000000001])\n",
    "                                    y_range_int = np.array([-1000000, 1000000])\n",
    "\n",
    "                                    fsize=10\n",
    "                                    mpl.rcParams.update({'font.size': 13})\n",
    "                                    mkSz = [0.1, 0.1, 0.15, 0.1, 0.1]\n",
    "                                    msz=40\n",
    "                                    yellow = (\"#fec44f\")\n",
    "                                    green = (\"#77dd77\")\n",
    "                                    red = (\"#ff6961\")\n",
    "                                    fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "\n",
    "                                    nonzero_bulk = np.where(bulk_press_time>0)[0]\n",
    "                                    nonzero_align = np.where(align_press_time>0)[0]\n",
    "                                    print(np.mean(bulk_press_time[nonzero_bulk]))\n",
    "                                    print(np.mean(align_press_time[nonzero_align]))\n",
    "                                    print(bulk_press_time[-1])\n",
    "                                    print(align_press_time[-1])\n",
    "                                    plt.plot(bulk_time[nonzero_bulk], bulk_press_time[nonzero_bulk],\n",
    "                                                   c=slowCol, lw=1.8*1.8,\n",
    "                                                   label='Bulk')\n",
    "                                    plt.plot(align_time[nonzero_align], align_press_time[nonzero_align],\n",
    "                                                   c=fastCol, lw=1.8*1.8,\n",
    "                                                   label='Interface')\n",
    "                                    ax1.plot(x_range_int, y_range_int, c='black', lw=1.5*1.2, ls='--')\n",
    "\n",
    "                                    ax1.set_xlim(0.0, 2.0)        \n",
    "                                    # y limits\n",
    "\n",
    "\n",
    "                                    ax1.set_ylim(-1000, 20000) \n",
    "\n",
    "\n",
    "                                    ax1.set_xlabel(r'time ($\\tau$)', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "\n",
    "                                    ax1.set_ylabel(r'Pressure ($\\Pi$)', fontsize=fsize*2.8)\n",
    "\n",
    "\n",
    "                                    # Set all the x ticks for radial plots\n",
    "                                    loc = ticker.MultipleLocator(base=0.2)\n",
    "                                    ax1.xaxis.set_major_locator(loc)\n",
    "                                    loc = ticker.MultipleLocator(base=0.1)\n",
    "                                    ax1.xaxis.set_minor_locator(loc)\n",
    "\n",
    "\n",
    "                                    # Set y ticks\n",
    "                                    loc = ticker.MultipleLocator(base=5000)\n",
    "                                    ax1.yaxis.set_major_locator(loc)\n",
    "                                    loc = ticker.MultipleLocator(base=2500)\n",
    "                                    ax1.yaxis.set_minor_locator(loc)\n",
    "                                    # Left middle plot\n",
    "                                    plt.legend(loc='upper right', fontsize=fsize*2.7)\n",
    "                                    props = dict(boxstyle='square', facecolor='white', edgecolor='none', alpha=0.85, pad=0.1)\n",
    "                                    props2 = dict(boxstyle='square', facecolor='white', edgecolor='none', alpha=0.85, pad=0.1)\n",
    "                                    ax1.text(0.2, 0.885, 'Compress', zorder=10,\n",
    "                                               transform=ax1.transAxes,\n",
    "                                               size=fsize*2.1, fontdict={'fontname':'Helvetica'}, bbox=props)\n",
    "                                    ax1.text(0.37, 0.885, 'Balanced', zorder=10,\n",
    "                                               transform=ax1.transAxes,\n",
    "                                               fontsize=fsize*2.1,fontdict={'fontname':'Helvetica'}, bbox=props)\n",
    "                                    ax1.tick_params(axis='x', labelsize=fsize*2.5)\n",
    "                                    ax1.tick_params(axis='y', labelsize=fsize*2.5)\n",
    "\n",
    "                                    plt.tight_layout()\n",
    "                                    plt.show()\n",
    "                                    #plt.savefig('radial_figure_test_prod_pres.png', bbox_inches='tight', pad_inches=0.02, dpi=200)\n",
    "                                    #plt.show()\n",
    "                                    #plt.close()\n",
    "\n",
    "                                    #plt.figure(figsize=(8,6))\n",
    "\n",
    "    \n",
    "\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import cm\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "        \n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "div_min = -3\n",
    "min_n = 0\n",
    "max_n = 20\n",
    "levels_text=40\n",
    "level_boundaries = np.linspace(min_n, max_n, levels_text + 1)\n",
    "tick_locs   = [0.0,np.pi/6,np.pi/3]\n",
    "tick_labels = ['0',r'$\\pi/6$',r'$\\pi/3$']\n",
    "\n",
    "im = plt.scatter(first_interpart_peNet, first_bulk_press, linewidths=1.0, edgecolor='black', facecolor='green', s=60.0)\n",
    "im = plt.scatter(first_align_peNet, first_align_press, linewidths=1.0, edgecolor='black', facecolor='yellow', s=60.0)\n",
    "         \n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Fast Interface')\n",
    "red_patch = mpatches.Patch(color='green', label='Slow Bulk')\n",
    "plt.legend(handles=[yellow_patch, red_patch], fancybox=True, framealpha=0.75, ncol=1, fontsize=12, loc='upper left',labelspacing=0.1, handletextpad=0.1)\n",
    "\n",
    "    \n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$', fontsize=20)\n",
    "plt.ylabel(r'Initial Pressure ($\\Pi$)', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10,7))\n",
    "ax = fig.add_subplot(111)\n",
    "div_min = -3\n",
    "min_n = 0\n",
    "max_n = 20\n",
    "levels_text=40\n",
    "level_boundaries = np.linspace(min_n, max_n, levels_text + 1)\n",
    "tick_locs   = [0.0,np.pi/6,np.pi/3]\n",
    "tick_labels = ['0',r'$\\pi/6$',r'$\\pi/3$']\n",
    "for i in range(0, len(first_bulk_press)):\n",
    "    for j in range(0, len(press_fast_dense)):\n",
    "        if (first_interpart_peA[i]==pa_pair[j]) and (first_interpart_peB[i]==pb_pair[j]):\n",
    "            im = plt.scatter(first_interpart_peNet[i], ((first_bulk_press[i] - press_slow_dense[j])/press_slow_dense[j])*100, linewidths=1.0, edgecolor='black', facecolor='green', s=60.0)\n",
    "        elif (first_interpart_peB[i]==pa_pair[j]) and (first_interpart_peA[i]==pb_pair[j]):\n",
    "            im = plt.scatter(first_interpart_peNet[i], ((first_bulk_press[i] - press_slow_dense[j])/press_slow_dense[j])*100, linewidths=1.0, edgecolor='black', facecolor='green', s=60.0)\n",
    "for i in range(0, len(first_align_press)):\n",
    "    for j in range(0, len(press_slow_int)):\n",
    "        if (first_align_peA[i]==pa_pair[j]) and (first_align_peB[i]==pb_pair[j]):\n",
    "            im = plt.scatter(first_align_peNet[i], ((first_align_press[i]-press_fast_int[j])/press_fast_int[j])*100, linewidths=1.0, edgecolor='black', facecolor='yellow', s=60.0)\n",
    "        elif (first_align_peB[i]==pa_pair[j]) and (first_align_peA[i]==pb_pair[j]):\n",
    "            im = plt.scatter(first_align_peNet[i], ((first_align_press[i]-press_fast_int[j])/press_fast_int[j])*100, linewidths=1.0, edgecolor='black', facecolor='yellow', s=60.0)\n",
    "yellow_patch = mpatches.Patch(color='yellow', label='Fast Interface')\n",
    "red_patch = mpatches.Patch(color='green', label='Slow Bulk')\n",
    "plt.legend(handles=[yellow_patch, red_patch], fancybox=True, framealpha=0.75, ncol=1, fontsize=12, loc='upper left',labelspacing=0.1, handletextpad=0.1)\n",
    "\n",
    "    \n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$', fontsize=20)\n",
    "plt.ylabel('Percent Error (%)', fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(first_interpart_peNet, first_bulk_press, s=10.0, color='blue', label='bulk interparticle')\n",
    "plt.scatter(first_align_peNet, first_align_press, s=10.0, color='red', label='aligned interface')\n",
    "\n",
    "\n",
    "plt.title('fast interface, slow bulk (stable)', fontsize=22)\n",
    "plt.ylabel(r'Initial Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend(loc='upper left')\n",
    "plt.ylim([-2500, 25000])\n",
    "plt.show() \n",
    "stop\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(interpart_peNet, interpart_press, c='blue', label='bulk interparticle')\n",
    "plt.scatter(align_peNet, align_press_arr, c='red', label='aligned interface')\n",
    "plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "'''\n",
    "for i in range(0, len(align_peA)):  \n",
    "    for j in range(0, len(align_peB)):  \n",
    "        for k in range(0, len(interpart_peA)):  \n",
    "            for l in range(0, len(interpart_peB)):  \n",
    "                if (align_peA[i]==interpart_peA[k]) & (align_peB[j]==interpart_peB[l]):\n",
    "                    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "\n",
    "\n",
    "for i in range(0, len(all_dens)):\n",
    "    \n",
    "    align_time =np.array([])\n",
    "    align_press_time = np.array([])\n",
    "    align_press_total = 0\n",
    "    align_press_vals=0\n",
    "    \n",
    "    # Don't plot non-phase-separated data\n",
    "    if all_dens[i].empty:\n",
    "            continue\n",
    "    \n",
    "    \n",
    "    max_size = np.amax(all_dens[i]['clust_size'])\n",
    "    for j in range(0, len(all_dens[i]['clust_size'])):\n",
    "        #if all_dens[i]['clust_size'][j]>=0.95*max_size:\n",
    "            int_id = all_dens[i]['interface_id'][j]\n",
    "            if int_id == 1:\n",
    "                align_press = all_dens[i]['press_align_bub1'][j]\n",
    "            elif int_id == 2:\n",
    "                align_press = all_dens[i]['press_align_bub2'][j]\n",
    "            elif int_id == 3:\n",
    "                align_press = all_dens[i]['press_align_bub3'][j]\n",
    "            elif int_id == 4:\n",
    "                align_press = all_dens[i]['press_align_bub4'][j]\n",
    "            elif int_id == 5:\n",
    "                align_press = all_dens[i]['press_align_bub5'][j]\n",
    "            if align_press > 0:\n",
    "                align_time = np.append(align_time, all_dens[i]['tauB'].iloc[j])\n",
    "                align_press_time = np.append(align_press_time, align_press)\n",
    "            \n",
    "                align_press_total += align_press\n",
    "                align_press_vals += 1\n",
    "    if align_press_vals > 50:        \n",
    "        avg_press = (align_press_total/align_press_vals)\n",
    "        align_press_arr = np.append(align_press_arr, avg_press)\n",
    "        align_peA=np.append(align_peA, params['peA'][i])\n",
    "        align_peB=np.append(align_peB, params['peB'][i])\n",
    "        align_peNet=np.append(align_peNet, params['peB'][i] * (1-params['xA'][i]/100) + params['peA'][i] * (params['xA'][i]/100))\n",
    "        align_xA=np.append(align_xA, params['xA'][i])\n",
    "        align_phi=np.append(align_phi, params['phi'][i])\n",
    "        align_eps=np.append(align_eps, params['eps'][i])\n",
    "    for k in range(0, len(all_pres)):\n",
    "        if params2['peA'][k]==params['peA'][i]:\n",
    "            if params2['peB'][k]==params['peB'][i]:\n",
    "                if params2['eps'][k]==params['eps'][i]:\n",
    "                    if params2['phi'][k]==params['phi'][i]:\n",
    "                        if params2['xA'][k]==params['xA'][i]:\n",
    "                            bulk_time =np.array([])\n",
    "                            bulk_press_time = np.array([])\n",
    "                            bulk_press_total = 0\n",
    "                            bulk_press_total_expand = 0\n",
    "                            bulk_press_vals=0\n",
    "                            shear_press_expand=0\n",
    "                            # Don't plot non-phase-separated data\n",
    "                            if all_pres[k].empty:\n",
    "                                    continue\n",
    "\n",
    "\n",
    "                            max_size = np.amax(all_pres[k]['NDense'])\n",
    "                            for l in range(0, len(all_pres[k]['NDense'])):\n",
    "                                #if all_pres[i]['NDense'][j]>=0.95*max_size:\n",
    "\n",
    "                                    bulk_trace = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2#+all_pres_new[i]['bulkSigYX'].iloc[-1]+all_pres_new[i]['bulkSigYY'].iloc[-1])/2\n",
    "                                    bulk_press = bulk_trace / (all_pres[k]['bulkArea'].iloc[l])\n",
    "\n",
    "                                    bulk_trace_expand = (all_pres[k]['bulkSigXX'].iloc[l]+all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l]+all_pres[k]['bulkSigYY'].iloc[l])/2\n",
    "                                    bulk_press_expand = bulk_trace_expand / (all_pres[k]['bulkArea'].iloc[l])\n",
    "\n",
    "                                    shear_stress = (all_pres[k]['bulkSigXY'].iloc[l]+all_pres[k]['bulkSigYX'].iloc[l])/2\n",
    "                                    shear_press = shear_stress / (all_pres[k]['bulkArea'].iloc[l])\n",
    "                                    if bulk_press>0:\n",
    "                                        bulk_time = np.append(bulk_time, all_pres[k]['Timestep'].iloc[l])\n",
    "                                        bulk_press_time = np.append(bulk_press_time, bulk_press/2)\n",
    "                                        shear_press_expand +=shear_press\n",
    "                                        bulk_press_total += bulk_press\n",
    "                                        bulk_press_total_expand += bulk_press_expand\n",
    "                                        bulk_press_vals += 1\n",
    "                            if bulk_press_vals > 50:        \n",
    "                                avg_shear = np.append(avg_shear, shear_press_expand/bulk_press_vals)\n",
    "                                avg_press = (bulk_press_total/(2*bulk_press_vals))\n",
    "                                avg_press_expand = (bulk_press_total_expand/bulk_press_vals)\n",
    "                                interpart_press=np.append(interpart_press, avg_press)\n",
    "                                interpart_press_expand=np.append(interpart_press_expand, avg_press_expand)\n",
    "                                interpart_peA=np.append(interpart_peA, params2['peA'][k])\n",
    "                                interpart_peB=np.append(interpart_peB, params2['peB'][k])\n",
    "                                interpart_peNet=np.append(interpart_peNet, params2['peB'][k] * (1-params2['xA'][k]/100) + params2['peA'][k] * (params2['xA'][k]/100))\n",
    "                                interpart_xA=np.append(interpart_xA, params2['xA'][k])\n",
    "                                interpart_phi=np.append(interpart_phi, params2['phi'][k])\n",
    "                                interpart_eps=np.append(interpart_eps, params2['eps'][k])\n",
    "                            \n",
    "                            plt.figure(figsize=(8,6))\n",
    "                            nonzero_bulk = np.where(bulk_press_time>0)[0]\n",
    "                            nonzero_align = np.where(align_press_time>0)[0]\n",
    "                            plt.plot(bulk_time[nonzero_bulk], bulk_press_time[nonzero_bulk], color='blue', label='bulk interparticle')\n",
    "                            plt.scatter(align_time[nonzero_align], align_press_time[nonzero_align], s=0.7, color='red', label='aligned interface')\n",
    "                            plt.title('fast interface, slow bulk (stable)', fontsize=22)\n",
    "                            plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "                            plt.xlabel(r'time ($\\tau$)')\n",
    "                            plt.legend()\n",
    "                            plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(interpart_peNet, interpart_press, c='blue', label='bulk interparticle')\n",
    "plt.scatter(align_peNet, align_press_arr, c='red', label='aligned interface')\n",
    "plt.ylabel(r'Pressure ($\\Pi$)')\n",
    "plt.xlabel(r'$\\mathrm{Pe}_\\mathrm{Net}$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "    \n",
    "'''\n",
    "for i in range(0, len(align_peA)):  \n",
    "    for j in range(0, len(align_peB)):  \n",
    "        for k in range(0, len(interpart_peA)):  \n",
    "            for l in range(0, len(interpart_peB)):  \n",
    "                if (align_peA[i]==interpart_peA[k]) & (align_peB[j]==interpart_peB[l]):\n",
    "                    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
