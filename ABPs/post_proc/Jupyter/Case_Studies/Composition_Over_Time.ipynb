{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the import cell\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (inset_axes, InsetPosition,\n",
    "                                                  mark_inset)\n",
    "import matplotlib.ticker as ticker\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from PIL import Image\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patches as patches\n",
    "import pylab as plot\n",
    "first = True\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option(\"display.max_rows\", 10)\n",
    "\n",
    "\n",
    "\n",
    "# Here are my rc parameters for matplotlibf\n",
    "fsize = 20\n",
    "mpl.rc('font', serif='Helvetica Neue')\n",
    "#mpl.rc('font', serif='Times New Roman')\n",
    "mpl.rcParams.update({'font.size': fsize})\n",
    "mpl.rcParams['figure.figsize'] = 3.2, 2.8\n",
    "mpl.rcParams['figure.dpi'] = 500\n",
    "mpl.rcParams['xtick.direction'] = 'in'\n",
    "mpl.rcParams['ytick.direction'] = 'in'\n",
    "mpl.rcParams['lines.linewidth'] = 1.5\n",
    "mpl.rcParams['axes.linewidth'] = 1.5\n",
    "# Set x tick params\n",
    "mpl.rcParams['xtick.major.size'] = 4.5\n",
    "mpl.rcParams['xtick.major.width'] = 1.5\n",
    "mpl.rcParams['xtick.minor.size'] = 3.\n",
    "mpl.rcParams['xtick.minor.width'] = 1.25\n",
    "# Set y tick params\n",
    "mpl.rcParams['ytick.major.size'] = 4.5\n",
    "mpl.rcParams['ytick.major.width'] = 1.5\n",
    "mpl.rcParams['ytick.minor.size'] = 3.\n",
    "mpl.rcParams['ytick.minor.width'] = 1.25\n",
    "mpl.rcParams['legend.fontsize']= 20.\n",
    "mpl.rcParams['mathtext.fontset'] = 'stix'\n",
    "mpl.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "# Load LaTeX and amsmath\n",
    "# mpl.rc('text', usetex=True)\n",
    "# mpl.rcParams['text.latex.preamble']=[r\"\\usepackage{amsmath}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current path\n",
    "if first:\n",
    "    parent = os.getcwd()\n",
    "os.chdir(parent)\n",
    "\n",
    "# Grab the MCS data\n",
    "pres2 = os.listdir('../../../../../../../../Volumes/EXTERNAL2/PhaseComp_test')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")\n",
    "    \n",
    "# Grab the MCS data\n",
    "pres4 = os.listdir('../../../../../../../../Volumes/EXTERNAL2/BubComp_test')\n",
    "try:\n",
    "    pres.remove('.DS_Store')\n",
    "except:\n",
    "    print(\".DS_Store not in directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some functions to get the relevant data from the filenames\n",
    "def checkFile(fname, string):\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "#             print\"{} matches {}\".format(fname[i], string[0])\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "#                     print\"{} matches {}\".format(fname[i+j], string[j])\n",
    "                    if j == (len(string) - 1):\n",
    "#                         print\"Final match!\"\n",
    "                        return True\n",
    "                else:\n",
    "                    break\n",
    "    return False\n",
    "    \n",
    "def txtValue(fname, string):\n",
    "    out = \"\"\n",
    "    index = 0\n",
    "    for i in range(len(fname)):\n",
    "        if fname[i] == string[0]:\n",
    "            for j in range(1, len(string)):\n",
    "                if (i + j) > (len(fname) - 1):\n",
    "                    break\n",
    "                elif fname[i + j] == string[j]:\n",
    "                    if j == (len(string) - 1):\n",
    "                        # Last index of search string\n",
    "                        index = i + j\n",
    "                else:\n",
    "                    break\n",
    "                        \n",
    "    # First index of value\n",
    "    index += 1\n",
    "    mybool = True\n",
    "    while mybool:\n",
    "        if fname[index].isdigit():\n",
    "            out = out + fname[index]\n",
    "            index += 1\n",
    "        elif fname[index] == \".\":    \n",
    "            if fname[index+1].isdigit():\n",
    "                out = out + fname[index]\n",
    "                index += 1\n",
    "            else:\n",
    "                mybool = False\n",
    "        else:\n",
    "            mybool = False\n",
    "    return float(out)\n",
    "\n",
    "# Sorting functions\n",
    "def multiSort(arr1, arr2, arr3, arr4):\n",
    "    \"\"\"Sort an array the slow (but certain) way, returns original indices in sorted order\"\"\"\n",
    "    # Doing this for PeR, PeS, xS in this case\n",
    "    cpy1 = np.copy(arr1)\n",
    "    cpy2 = np.copy(arr2)\n",
    "    cpy3 = np.copy(arr3)\n",
    "    cpy4 = np.copy(arr4)\n",
    "    ind = np.arange(0, len(arr1))\n",
    "    for i in range(len(cpy1)):\n",
    "        for j in range(len(cpy1)):\n",
    "            # Sort by first variable\n",
    "            if cpy1[i] > cpy1[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            # If first variable is equal, resort to second variable\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] > cpy2[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "                \n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] > cpy3[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "            elif cpy1[i] == cpy1[j] and cpy2[i] == cpy2[j] and cpy3[i] == cpy3[j] and cpy4[i] > cpy4[j] and i < j:\n",
    "                # Swap copy array values\n",
    "                cpy1[i], cpy1[j] = cpy1[j], cpy1[i]\n",
    "                cpy2[i], cpy2[j] = cpy2[j], cpy2[i]\n",
    "                cpy3[i], cpy3[j] = cpy3[j], cpy3[i]\n",
    "                cpy4[i], cpy4[j] = cpy4[j], cpy4[i]\n",
    "                # Swap the corresponding indices\n",
    "                ind[i], ind[j] = ind[j], ind[i]\n",
    "    return ind\n",
    "\n",
    "def indSort(arr1, arr2):\n",
    "    \"\"\"Take sorted index array, use to sort array\"\"\"\n",
    "    # arr1 is array to sort\n",
    "    # arr2 is index array\n",
    "    cpy = np.copy(arr1)\n",
    "    for i in range(len(arr1)):\n",
    "        arr1[i] = cpy[arr2[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres2:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres2, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/PhaseComp_test')\n",
    "for i in pres2:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params3 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params3 = params3.append(df, ignore_index = True)\n",
    "display(params3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new[i].fillna(0, inplace=True)\n",
    "\n",
    "headers=list(all_pres_new[0])\n",
    "display(all_pres_new[0])\n",
    "print(all_pres_new[0][headers[1]][0])\n",
    "print(all_pres_new[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab parameters, sort them\n",
    "chkStrings = [\"pe\", \"pa\", \"pb\", \"xa\", \"eps\", \"phi\", \"cluster\", \"dtau\"]\n",
    "default = [0., 0., 0., 100., 1., 60., 0, 0.000001]\n",
    "storeVals = [[] for i in chkStrings]\n",
    "for i in pres4:\n",
    "    for j in range(0, len(chkStrings)):\n",
    "        if chkStrings[j] != \"cluster\":\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(txtValue(i, chkStrings[j]))\n",
    "            else:\n",
    "                storeVals[j].append(default[j])  \n",
    "        else:\n",
    "            if checkFile(i, chkStrings[j]):\n",
    "                storeVals[j].append(1)\n",
    "            else:\n",
    "                storeVals[j].append(default[j]) \n",
    "\n",
    "# Issue with epsilon in file output 0 -> 0.0001\n",
    "for i in range(0, len(storeVals[4])):\n",
    "    if storeVals[4][i] == 0.0:\n",
    "        storeVals[4][i] = 0.0001\n",
    "\n",
    "# Sort the arrays\n",
    "if len(storeVals[0]) > 1:\n",
    "    # Sort them!\n",
    "#     print(\"Sorting... \")\n",
    "    # Sort by: pe, phi, epsilon, cluster\n",
    "    indArr = multiSort(storeVals[chkStrings.index(\"pa\")],\n",
    "                       storeVals[chkStrings.index(\"phi\")],\n",
    "                       storeVals[chkStrings.index(\"eps\")],\n",
    "                       storeVals[chkStrings.index(\"cluster\")])\n",
    "    indSort(pres4, indArr)\n",
    "    for i in storeVals:\n",
    "        indSort(i, indArr)\n",
    "    \n",
    "# Now that the data is sorted, read it into a dataframe\n",
    "all_pres_new3 = []\n",
    "os.chdir(parent)\n",
    "os.chdir('../../../../../../../../Volumes/EXTERNAL2/BubComp_test')\n",
    "for i in pres4:\n",
    "#     print(i)\n",
    "    df = pd.read_csv(i, sep='\\s+', header=0)\n",
    "    all_pres_new3.append(df)\n",
    "os.chdir(parent)\n",
    "\n",
    "# This is how you access the data at different levels\n",
    "display(all_pres_new3[-1])\n",
    "print(storeVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the parameters from each file, store in a dataframe\n",
    "headers = ['pe', 'peA', 'peB', 'xA', 'eps', 'phi', 'tauPer_dt']\n",
    "params5 = pd.DataFrame(columns=headers)\n",
    "for i in range(0, len(all_pres_new3)):\n",
    "    pe = int(storeVals[chkStrings.index(\"pe\")][i])\n",
    "    pa = int(storeVals[chkStrings.index(\"pa\")][i])\n",
    "    pb = int(storeVals[chkStrings.index(\"pb\")][i])\n",
    "    xa = float(storeVals[chkStrings.index(\"xa\")][i])\n",
    "    ep = float(storeVals[chkStrings.index(\"eps\")][i])\n",
    "    phi = float(storeVals[chkStrings.index(\"phi\")][i])\n",
    "    dtau = float(storeVals[chkStrings.index(\"dtau\")][i])\n",
    "    df = pd.DataFrame([[pe, pa, pb, xa, ep, phi, dtau]], columns=headers)\n",
    "    params5 = params5.append(df, ignore_index = True)\n",
    "display(params5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add columns to the time-resolved simulation data\n",
    "for i in range(len(all_pres_new3)):\n",
    "    # Ger rid of NaN in favor of 0\n",
    "    all_pres_new3[i].fillna(0, inplace=True)\n",
    "headers=list(all_pres_new3[0])\n",
    "display(all_pres_new3[0])\n",
    "print(all_pres_new3[0][headers[1]][0])\n",
    "print(all_pres_new3[0][headers[2]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All data is loaded, now compute analytical aspects\n",
    "r_cut = (2.**(1./6.))\n",
    "\n",
    "# Get lattice spacing for particle size\n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / sigma) * ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "# # Lennard-Jones pressure\n",
    "# def ljPress(r, eps, sigma=1.):\n",
    "#     phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "#     div = (sigma/r)\n",
    "#     dU = (24. * eps / r) * ((2.*(div**12.)) - (div)**6.)\n",
    "#     # This is just pressure divided by the area of a particle\n",
    "# #     return (12. * dU / (np.pi * r))\n",
    "#     return (12. * dU / (np.pi * r * phiCP))\n",
    "\n",
    "def ljPress(r, pe, eps, sigma=1.):\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    # This is off by a factor of 1.2...\n",
    "    ljF = avgCollisionForce(pe)\n",
    "    return (2. *np.sqrt(3) * ljF / r)\n",
    "    \n",
    "def avgCollisionForce(pe, power=1.):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    peCritical = 40.\n",
    "    if pe < peCritical:\n",
    "        pe = 0\n",
    "    else:\n",
    "        pe -= peCritical\n",
    "    magnitude = 6.\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "#     return (magnitude * (pe**power)) / (np.pi)\n",
    "#     return (pe * (1. + (8./(np.pi**2.))))\n",
    "    coeff = 1.764#1.92#2.03#3.5#2.03\n",
    "    #coeff= 0.4053\n",
    "    return (pe * coeff)\n",
    "\n",
    "def fStar(pe, epsilon, sigma=1.):\n",
    "    out = (avgCollisionForce(pe) * sigma) / (24.*epsilon)\n",
    "    return out\n",
    "    \n",
    "def conForRClust(pe, eps):\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(pe):\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "\n",
    "def nonDimFLJ(r, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "def latForFStar(fstar):\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while nonDimFLJ(r) < fstar:\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "    \n",
    "def latToPhi(latIn):\n",
    "    '''Read in lattice spacing, output phi'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    return phiCP / (latIn**2)\n",
    "\n",
    "# From area fraction, get lattice spacing\n",
    "def phiToLat(phiIn):\n",
    "    '''Read in phi, output the lattice spacing'''\n",
    "    phiCP = np.pi / (2. * np.sqrt(3.))\n",
    "    latCP = 1.\n",
    "    return np.sqrt(phiCP / phiIn)\n",
    "    \n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    return num / den\n",
    "    \n",
    "def clustFrac(phi, phiG, a, sig=1.):\n",
    "    phiL = latToPhi(a)\n",
    "    ApL = np.pi * (sig**2) / 4.\n",
    "    Ap = np.pi * (sig**2) / 4.\n",
    "    num = (phiL*phiG) - (phiL*phi)\n",
    "    den = (phi*phiG) - (phi*phiL)\n",
    "    ans = num / den\n",
    "    return ans\n",
    "\n",
    "def radCurve(area):\n",
    "    # From area of circle get curvature\n",
    "    return np.sqrt(area/np.pi)\n",
    "\n",
    "def radCirc(circ):\n",
    "    return circ / (2. * np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use analytical theory and kinetic theory to get cluster radius\n",
    "epsRange = [1., 0.1, 0.01, 0.001, 0.0001]\n",
    "# epsRange = [0.0001, 0.001, 0.01, 0.1, 1.]\n",
    "peRange = np.arange(0., 700., 1.)\n",
    "phiRange = [0.45, 0.55, 0.65]\n",
    "N = 100000.\n",
    "norm = 10.**0.\n",
    "# norm = 1.\n",
    "\n",
    "phiCP = np.pi / (2. * np.sqrt(3))\n",
    "lat = []\n",
    "pColl = []\n",
    "pLJ = []\n",
    "cfs = []\n",
    "Rls = []\n",
    "peCrit = []\n",
    "phiGs = []\n",
    "phiCPs = []\n",
    "a_box = []\n",
    "l_box = []\n",
    "for b in range(0, len(phiRange)):\n",
    "    lat.append([])\n",
    "    phiCPs.append([])\n",
    "    pColl.append([])\n",
    "    pLJ.append([])\n",
    "    cfs.append([])\n",
    "    Rls.append([])\n",
    "    phiGs.append([])\n",
    "    peCrit.append([])\n",
    "    a_box.append(N * np.pi * 0.25 / phiRange[b])\n",
    "    l_box.append(np.sqrt(a_box[-1]))\n",
    "    for i in range(0, len(epsRange)):\n",
    "        lat[b].append([])\n",
    "        phiCPs[b].append([])\n",
    "        pColl[b].append([])\n",
    "        pLJ[b].append([])\n",
    "        cfs[b].append([])\n",
    "        Rls[b].append([])\n",
    "        phiGs[b].append([])\n",
    "        for j in range(0, len(peRange)):\n",
    "            # Compute lattice spacing\n",
    "        \n",
    "            lat[b][i].append(conForRClust(peRange[j], epsRange[i]))\n",
    "            phiCPs[b][i].append(latToPhi(lat[b][i][-1]))\n",
    "            # Compute pressure\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP)\n",
    "            #curPLJ = ljPress(lat[b][i][-1], epsRange[i]) / (np.pi * (lat[b][i][-1]**2) * 0.25 * phiCP * (lat[b][i][-1]**(0.5)) * 1.25)\n",
    "            curPLJ = ljPress(lat[b][i][-1], peRange[j], epsRange[i])\n",
    "            \n",
    "            # Append to list\n",
    "            pLJ[b][i].append(curPLJ/(norm))\n",
    "\n",
    "            # Compute cluster fraction\n",
    "            phiG = compPhiG(peRange[j], lat[b][i][-1])\n",
    "            phiGs[b][i].append(phiG)\n",
    "            if peRange[j] > 35.:\n",
    "                cf = clustFrac(phiRange[b], phiG, lat[b][i][-1])\n",
    "                if cf < 0. or cf > 1.:\n",
    "                    cf = 0.\n",
    "            else:\n",
    "                cf = 0\n",
    "            cfs[b][i].append(cf)\n",
    "\n",
    "            # Get the critical activity\n",
    "            if j > 0:\n",
    "                if cfs[b][i][-2] == 0. and cfs[b][i][-1] > 0.:\n",
    "                    peCrit[b].append(peRange[j])\n",
    "\n",
    "            # Get the radius (for some N)\n",
    "            Nl = cfs[b][i][-1] * N\n",
    "            Al = Nl * ((np.pi * (lat[b][i][-1]**2))/(4*phiCP))\n",
    "            Rl = np.sqrt(Al / (np.pi))\n",
    "            Rls[b][i].append(Rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpart_peA=np.array([])\n",
    "interpart_peB=np.array([])\n",
    "interpart_peNet=np.array([])\n",
    "interpart_xA=np.array([])\n",
    "interpart_eps=np.array([])\n",
    "interpart_pnum=np.array([])\n",
    "interpart_phi=np.array([])\n",
    "interpart_press=np.array([])\n",
    "interpart_press_expand=np.array([])\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "phase_peA=np.array([])\n",
    "phase_peB=np.array([])\n",
    "phase_peRat=np.array([])\n",
    "phase_peDif=np.array([])\n",
    "phase_peNet=np.array([])\n",
    "phase_xA=np.array([])\n",
    "phase_eps=np.array([])\n",
    "phase_pnum=np.array([])\n",
    "phase_phi=np.array([])\n",
    "avg_bulk_nA = np.array([])\n",
    "avg_bulk_nB = np.array([])\n",
    "avg_int_nA = np.array([])\n",
    "avg_int_nB = np.array([])\n",
    "avg_gas_nA = np.array([])\n",
    "avg_gas_nB = np.array([])\n",
    "beta_arr = np.array([])\n",
    "beta_peNet = np.array([])\n",
    "avg_shear=np.array([])\n",
    "bulk_lat_mean = np.array([])\n",
    "beta_arr2 = np.array([])\n",
    "int_lat_mean = np.array([])\n",
    "all_lat_mean = np.array([])\n",
    "beta_arr2_std = np.array([])\n",
    "\n",
    "avg_bulk_nA = np.array([])\n",
    "avg_bulk_nB = np.array([])\n",
    "avg_bulk_n = np.array([])\n",
    "avg_dense_nA = np.array([])\n",
    "avg_dense_nB = np.array([])\n",
    "avg_dense_n = np.array([])\n",
    "avg_int_n = np.array([])\n",
    "\n",
    "avg_int_nA = np.array([])\n",
    "avg_int_nB = np.array([])\n",
    "avg_gas_nA = np.array([])\n",
    "avg_gas_nB = np.array([])\n",
    "beta_final_arr=np.array([])\n",
    "time_arr3 = np.array([])\n",
    "\n",
    "def ljForce(r, eps, sigma=1.):\n",
    "    div = (sigma/r)\n",
    "    dU = (24. * eps / sigma) * ((2*(div**13)) - (div)**7)\n",
    "    return dU\n",
    "\n",
    "def avgCollisionForce(pe, power=1.):\n",
    "    '''Computed from the integral of possible angles'''\n",
    "    peCritical = 40.\n",
    "    if pe < peCritical:\n",
    "        pe = 0\n",
    "    else:\n",
    "        pe -= peCritical\n",
    "    magnitude = 6.\n",
    "    # A vector sum of the six nearest neighbors\n",
    "    magnitude = np.sqrt(28)\n",
    "#     return (magnitude * (pe**power)) / (np.pi)\n",
    "#     return (pe * (1. + (8./(np.pi**2.))))\n",
    "    coeff = 1.874#3.0#1.92#2.03#3.5#2.03\n",
    "    #coeff= 0.4053\n",
    "    return (pe * coeff)\n",
    "\n",
    "def conForRClust(pe, eps):\n",
    "    out = []\n",
    "    r = 1.112\n",
    "    skip = [0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001, 0.0000001, 0.00000001]\n",
    "    for j in skip:\n",
    "        while ljForce(r, eps) < avgCollisionForce(pe):\n",
    "            r -= j\n",
    "        r += j\n",
    "    out = r\n",
    "    return out\n",
    "\n",
    "def densProbability(r, activity_net, activity_slow):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    gas_dense_dif_phi = 0.866 * np.log10(activity_net - 46.993) - 0.443\n",
    "    rate_decay = -6.151 * np.log10(activity_net-49.921) - 4.392\n",
    "    mid_point = 0.044 * np.log10(activity_slow-49.893) + 0.836\n",
    "    gas_phi = -0.26 * np.log10(activity_slow-41.742)+0.783\n",
    "    \n",
    "    num_dens_r = ((gas_dense_dif_phi / (1+np.exp(-rate_decay * (r-mid_point)))) + gas_phi)\n",
    "    \n",
    "    return num_dens_r\n",
    "\n",
    "def alignProbability(r, activity_net, activity_slow):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    max_align = 0.2019 * np.log10(activity_net - 41.2803) - 0.1885\n",
    "    mid_point = 0.0492 * np.log10(activity_slow - 47.0061) + 0.8220\n",
    "    std_dev = 0.1057\n",
    "    align_r = max_align * np.exp(-(r-mid_point)**2/(2*std_dev**2))\n",
    "    \n",
    "    return align_r\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return int(idx)\n",
    "\n",
    "def activityProbability(r, r_swap = [], probA = []):\n",
    "    \"Using similar triangles to find sides\"\n",
    "    if len(r_swap)>0:\n",
    "        prob_rA = np.zeros(len(r))\n",
    "        prob_rB = np.zeros(len(r))\n",
    "        for i in range(1, len(r_swap)):\n",
    "            r_min = find_nearest(r, r_swap[i-1])\n",
    "            r_max = find_nearest(r, r_swap[i])\n",
    "            \n",
    "            prob_rA[r_min:r_max+1]=probA[i]\n",
    "            prob_rB[r_min:r_max+1]=1.0-probA[i]\n",
    "    else:\n",
    "        prob_rA = np.ones(len(r)) * 0.5\n",
    "        prob_rB = np.ones(len(r)) - prob_rA\n",
    "    \n",
    "    return prob_rA, prob_rB\n",
    "def compPhiG(pe, a, kap=4.5, sig=1.):\n",
    "    '''\n",
    "    Purpose: Compute analytical area fraction of the gas phase at steady state\n",
    "    given activity and lattice spacing\n",
    "    \n",
    "    Inputs: \n",
    "        pe: net activity (peclet number)\n",
    "        a: lattice spacing \n",
    "        kap: fitting parameter (default=4.5, shown by Redner)\n",
    "        sig: particle diameter (default=1.0)\n",
    "    \n",
    "    Output: Area fraction of the gas phase at steady state\n",
    "    '''\n",
    "    num = 3. * (np.pi**2) * kap * sig\n",
    "    den = 4. * pe * a\n",
    "    return num / den\n",
    "align_peA=np.array([])\n",
    "align_peB=np.array([])\n",
    "align_peNet=np.array([])\n",
    "first_align_peNet=np.array([])\n",
    "\n",
    "align_xA=np.array([])\n",
    "align_eps=np.array([])\n",
    "align_pnum=np.array([])\n",
    "align_phi=np.array([])\n",
    "align_press_arr = np.array([])\n",
    "first_align_press = np.array([])\n",
    "first_align_peA=np.array([])\n",
    "first_align_peB=np.array([])\n",
    "\n",
    "def areaType(Nx, latx):\n",
    "    Ax = Nx * np.pi * 0.25 * (latx**2)\n",
    "    return Ax\n",
    "\n",
    "press_interpart = np.array([])\n",
    "press_int2 = np.array([])\n",
    "\n",
    "beta_test_arr = np.array([])\n",
    "\n",
    "for n in range(0, len(all_pres_new)):\n",
    "\n",
    "    time_arr3 = np.array([])\n",
    "    bulk_nA_arr = np.array([])\n",
    "    bulk_nB_arr = np.array([])\n",
    "    bulk_n_arr = np.array([])\n",
    "    int_n_arr = np.array([])\n",
    "    int_nA_arr = np.array([])\n",
    "    int_nB_arr = np.array([])\n",
    "    gas_nA_arr = np.array([])\n",
    "    gas_nB_arr = np.array([])\n",
    "    dense_nA_arr = np.array([])\n",
    "    dense_nB_arr = np.array([])\n",
    "    dense_n_arr = np.array([])\n",
    "\n",
    "    for j in range(0, len(all_pres_new[n]['clust_size'])):\n",
    "        bin_size = all_pres_new[n]['sizeBin'][j]\n",
    "        bin_area = bin_size**2\n",
    "        time_arr3 = np.append(time_arr3, all_pres_new[n]['tauB'][j])\n",
    "        bulk_nA_arr = np.append(bulk_nA_arr, all_pres_new[n]['Na_bulk'][j] / (bin_area * all_pres_new[n]['NBin_bulk'][j]))\n",
    "        bulk_nB_arr = np.append(bulk_nB_arr, all_pres_new[n]['Nb_bulk'][j] / (bin_area * all_pres_new[n]['NBin_bulk'][j]))\n",
    "        bulk_n_arr = np.append(bulk_n_arr, (all_pres_new[n]['Nb_bulk'][j]+all_pres_new[n]['Na_bulk'][j]) / (bin_area * all_pres_new[n]['NBin_bulk'][j]))\n",
    "        int_n_arr = np.append(int_n_arr, (all_pres_new[n]['Na_int'][j]+all_pres_new[n]['Nb_int'][j]) / (bin_area * all_pres_new[n]['NBin_int'][j]))\n",
    "        int_nA_arr = np.append(int_nA_arr, all_pres_new[n]['Na_int'][j] / (bin_area * all_pres_new[n]['NBin_int'][j]))\n",
    "        int_nB_arr = np.append(int_nB_arr, all_pres_new[n]['Nb_int'][j] / (bin_area * all_pres_new[n]['NBin_int'][j]))\n",
    "        gas_nA_arr = np.append(gas_nA_arr, all_pres_new[n]['Na_gas'][j] / (bin_area * all_pres_new[n]['NBin_gas'][j]))\n",
    "        gas_nB_arr = np.append(gas_nB_arr, all_pres_new[n]['Nb_gas'][j] / (bin_area * all_pres_new[n]['NBin_gas'][j]))\n",
    "        dense_n_arr = np.append(dense_n_arr, (all_pres_new[n]['Na_int'][j]+all_pres_new[n]['Nb_int'][j]+all_pres_new[n]['Na_bulk'][j]+all_pres_new[n]['Nb_bulk'][j]) / (bin_area * (all_pres_new[n]['NBin_int'][j]+all_pres_new[n]['NBin_bulk'][j])))\n",
    "        dense_nA_arr = np.append(dense_nA_arr, (all_pres_new[n]['Na_int'][j]+all_pres_new[n]['Na_bulk'][j]) / (bin_area * (all_pres_new[n]['NBin_int'][j]+all_pres_new[n]['NBin_bulk'][j])))\n",
    "        dense_nB_arr = np.append(dense_nB_arr, (all_pres_new[n]['Nb_int'][j]+all_pres_new[n]['Nb_bulk'][j]) / (bin_area * (all_pres_new[n]['NBin_int'][j]+all_pres_new[n]['NBin_bulk'][j])))\n",
    "\n",
    "    \n",
    "    avg_bulk_nA = np.append(avg_bulk_nA, np.mean(bulk_nA_arr))\n",
    "    avg_bulk_n = np.append(avg_bulk_n, np.mean(bulk_n_arr))\n",
    "    avg_bulk_nB = np.append(avg_bulk_nB, np.mean(bulk_nB_arr))\n",
    "    avg_int_n = np.append(avg_int_n, np.mean(int_n_arr))\n",
    "\n",
    "    avg_int_nA = np.append(avg_int_nA, np.mean(int_nA_arr))\n",
    "    avg_int_nB = np.append(avg_int_nB, np.mean(int_nB_arr))\n",
    "    avg_gas_nA = np.append(avg_gas_nA, np.mean(gas_nA_arr))\n",
    "    avg_gas_nB = np.append(avg_gas_nB, np.mean(gas_nB_arr))\n",
    "    avg_dense_nA = np.append(avg_dense_nA, np.mean(dense_nA_arr))\n",
    "    avg_dense_n = np.append(avg_dense_n, np.mean(dense_n_arr))\n",
    "    avg_dense_nB = np.append(avg_dense_nB, np.mean(dense_nB_arr))\n",
    "\n",
    "    phase_peA=np.append(phase_peA, params3['peA'][n])\n",
    "    phase_peB=np.append(phase_peB, params3['peB'][n])\n",
    "    phase_peDif=np.append(phase_peDif, params3['peB'][n]-params3['peA'][n])\n",
    "    phase_peRat=np.append(phase_peRat, params3['peA'][n]/params3['peB'][n])\n",
    "\n",
    "    phase_peNet=np.append(phase_peNet, params3['peB'][n] * (1-params3['xA'][n]/100) + params3['peA'][n] * (params3['xA'][n]/100))\n",
    "    phase_xA=np.append(phase_xA, params3['xA'][n])\n",
    "    phase_phi=np.append(phase_phi, params3['phi'][n])\n",
    "    phase_eps=np.append(phase_eps, params3['eps'][n])\n",
    "\n",
    "    fastCol = '#e31a1c'\n",
    "    slowCol = '#081d58'\n",
    "    print(phase_peA)\n",
    "    print(phase_peB)\n",
    "    fig, ax1 = plt.subplots(figsize=(12,5))\n",
    "    plt.plot(time_arr3, bulk_nA_arr, '-', color=slowCol, label='Slow',lw=1.8*1.8)\n",
    "    plt.plot(time_arr3, bulk_nB_arr, '-', color=fastCol, label='Fast',lw=1.8*1.8)\n",
    "\n",
    "    # Set all the x ticks for radial plots\n",
    "    loc = ticker.MultipleLocator(base=100)\n",
    "    ax1.xaxis.set_major_locator(loc)\n",
    "    loc = ticker.MultipleLocator(base=50)\n",
    "    ax1.xaxis.set_minor_locator(loc)\n",
    "    # Set y ticks\n",
    "    #loc = ticker.MultipleLocator(base=0.5)\n",
    "    #ax1.yaxis.set_major_locator(loc)\n",
    "    #loc = ticker.MultipleLocator(base=0.25)\n",
    "    #ax1.yaxis.set_minor_locator(loc)\n",
    "\n",
    "\n",
    "    ax1.tick_params(axis='x', labelsize=26)\n",
    "    ax1.tick_params(axis='y', labelsize=26)\n",
    "    ax1.set_xlabel(r'Time ($x=\\tau$)', fontsize=32)\n",
    "    ax1.set_ylabel(r'Number Density ($n$)', fontsize=32)\n",
    "    #ax1.set_ylim([-0.05,1.05])\n",
    "    props = dict(boxstyle='square', facecolor='white', edgecolor='none', alpha=0.85, pad=0.1)\n",
    "    #ax1.text(0.44, 0.88, r'$n(x)=(0.0023\\mathrm{Pe}_\\mathrm{Net}+1.0194)/(1+e^{18.8699(x-0.92902)})+(-0.000683\\mathrm{Pe}_\\mathrm{Net}+0.3534)$', zorder=10,\n",
    "    #           transform=ax1.transAxes,\n",
    "    #           fontsize=22,fontdict={'fontname':'Helvetica'}, bbox=props)  \n",
    "    plt.legend(loc='upper right', fontsize=28)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
